{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## AdaBoost\n",
    "### AdaBoost is a boosting algorithm which combines multiple weak classifiers to create a strong classifier. In this notebook, we will use AdaBoost to classify the quality of apples based on their features. Comparing this algorithm to other classification algorithms."
   ],
   "id": "8e013c3d9d14e4fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading the dataset",
   "id": "5c5ea2d2d0b0ba3b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-11T13:24:30.495432Z",
     "start_time": "2024-11-11T13:24:30.477754Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"./apple_quality.csv\")\n",
    "\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   A_id      Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n",
       "0     0 -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840   \n",
       "1     1 -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530   \n",
       "2     2 -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033   \n",
       "3     3 -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761   \n",
       "4     4  1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849   \n",
       "\n",
       "    Acidity Quality  \n",
       "0 -0.491590    good  \n",
       "1 -0.722809    good  \n",
       "2  2.621636     bad  \n",
       "3  0.790723    good  \n",
       "4  0.501984    good  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_id</th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.970049</td>\n",
       "      <td>-2.512336</td>\n",
       "      <td>5.346330</td>\n",
       "      <td>-1.012009</td>\n",
       "      <td>1.844900</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>-0.491590</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.195217</td>\n",
       "      <td>-2.839257</td>\n",
       "      <td>3.664059</td>\n",
       "      <td>1.588232</td>\n",
       "      <td>0.853286</td>\n",
       "      <td>0.867530</td>\n",
       "      <td>-0.722809</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.292024</td>\n",
       "      <td>-1.351282</td>\n",
       "      <td>-1.738429</td>\n",
       "      <td>-0.342616</td>\n",
       "      <td>2.838636</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>2.621636</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.657196</td>\n",
       "      <td>-2.271627</td>\n",
       "      <td>1.324874</td>\n",
       "      <td>-0.097875</td>\n",
       "      <td>3.637970</td>\n",
       "      <td>-3.413761</td>\n",
       "      <td>0.790723</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.364217</td>\n",
       "      <td>-1.296612</td>\n",
       "      <td>-0.384658</td>\n",
       "      <td>-0.553006</td>\n",
       "      <td>3.030874</td>\n",
       "      <td>-1.303849</td>\n",
       "      <td>0.501984</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:24:30.538792Z",
     "start_time": "2024-11-11T13:24:30.528972Z"
    }
   },
   "cell_type": "code",
   "source": "data.info()\n",
   "id": "747494c62c2f2d6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   A_id         4000 non-null   int64  \n",
      " 1   Size         4000 non-null   float64\n",
      " 2   Weight       4000 non-null   float64\n",
      " 3   Sweetness    4000 non-null   float64\n",
      " 4   Crunchiness  4000 non-null   float64\n",
      " 5   Juiciness    4000 non-null   float64\n",
      " 6   Ripeness     4000 non-null   float64\n",
      " 7   Acidity      4000 non-null   float64\n",
      " 8   Quality      4000 non-null   object \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 281.4+ KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:24:30.589363Z",
     "start_time": "2024-11-11T13:24:30.583175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Checking for missing values\n",
    "\n",
    "data.isnull().sum()"
   ],
   "id": "7bf4bb82313394c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A_id           0\n",
       "Size           0\n",
       "Weight         0\n",
       "Sweetness      0\n",
       "Crunchiness    0\n",
       "Juiciness      0\n",
       "Ripeness       0\n",
       "Acidity        0\n",
       "Quality        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:24:31.571882Z",
     "start_time": "2024-11-11T13:24:30.704215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Encode target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "data['Quality']=le.fit_transform(data['Quality'])\n",
    "data.head()"
   ],
   "id": "7be8089315ac676f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   A_id      Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness  \\\n",
       "0     0 -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840   \n",
       "1     1 -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530   \n",
       "2     2 -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033   \n",
       "3     3 -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761   \n",
       "4     4  1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849   \n",
       "\n",
       "    Acidity  Quality  \n",
       "0 -0.491590        1  \n",
       "1 -0.722809        1  \n",
       "2  2.621636        0  \n",
       "3  0.790723        1  \n",
       "4  0.501984        1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_id</th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.970049</td>\n",
       "      <td>-2.512336</td>\n",
       "      <td>5.346330</td>\n",
       "      <td>-1.012009</td>\n",
       "      <td>1.844900</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>-0.491590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.195217</td>\n",
       "      <td>-2.839257</td>\n",
       "      <td>3.664059</td>\n",
       "      <td>1.588232</td>\n",
       "      <td>0.853286</td>\n",
       "      <td>0.867530</td>\n",
       "      <td>-0.722809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.292024</td>\n",
       "      <td>-1.351282</td>\n",
       "      <td>-1.738429</td>\n",
       "      <td>-0.342616</td>\n",
       "      <td>2.838636</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>2.621636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.657196</td>\n",
       "      <td>-2.271627</td>\n",
       "      <td>1.324874</td>\n",
       "      <td>-0.097875</td>\n",
       "      <td>3.637970</td>\n",
       "      <td>-3.413761</td>\n",
       "      <td>0.790723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.364217</td>\n",
       "      <td>-1.296612</td>\n",
       "      <td>-0.384658</td>\n",
       "      <td>-0.553006</td>\n",
       "      <td>3.030874</td>\n",
       "      <td>-1.303849</td>\n",
       "      <td>0.501984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocess\n",
    "### We will need to separate the features and the target variable. For this dataset more preprocessing is not required as all data is numericall, there are no missing values and the target variable is already encoded. We will remove the column A_id as it is does not provide any useful information."
   ],
   "id": "c895fa1a01a3061f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:24:31.684082Z",
     "start_time": "2024-11-11T13:24:31.601386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Remove the A_id column\n",
    "data.drop('A_id',axis=1,inplace=True)\n",
    "\n",
    "#Separate the features and target variable\n",
    "X=data.drop('Quality',axis=1)\n",
    "y=data['Quality']\n",
    "\n",
    "#Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ],
   "id": "8f83b42820faa835",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## AdaBoost \n",
    "### We will use the AdaBoostClassifier from the sklearn library to classify the quality of apples. We will use the default parameters for now."
   ],
   "id": "ae45528fd90bd8b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:24:32.155570Z",
     "start_time": "2024-11-11T13:24:31.778048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Use AdaBoost with the default parameters\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "ada=AdaBoostClassifier()\n",
    "ada.fit(X_train,y_train)\n",
    "y_pred=ada.predict(X_test)\n",
    "\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred))\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))"
   ],
   "id": "81998cf963d1f952",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.7727272727272727\n",
      "Accuracy:  0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparison with other default classifier",
   "id": "b535426a9eba8a47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:24:33.140511Z",
     "start_time": "2024-11-11T13:24:32.325309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "svc=SVC()\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_rf=rf.predict(X_test)\n",
    "y_pred_svc=svc.predict(X_test)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred_rf))\n",
    "\n",
    "print(\"SVC\")\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred_svc))\n",
    "\n"
   ],
   "id": "381f446b26f16a6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "F1 Score:  0.9048207663782447\n",
      "SVC\n",
      "F1 Score:  0.9077306733167082\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### As we can see with default parameters AdaBoost performs worse than Random Forest and SVC. We can try to tune the parameters to improve the performance of AdaBoost. Therefore, we will now try to tune the parameters of AdaBoost to improve its performance.\n",
    "\n",
    "\n",
    "### We first tried with little estimators and performed worse than a default Random Forest"
   ],
   "id": "789742a0c7842eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:24:33.752873Z",
     "start_time": "2024-11-11T13:24:33.169585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Try adaboost with n estimators 2,4,10 and compare the best with random forest f1-score\n",
    "ada=AdaBoostClassifier(n_estimators=2)\n",
    "ada.fit(X_train,y_train)\n",
    "y_pred=ada.predict(X_test)\n",
    "\n",
    "print(\"AdaBoost with 2 estimators\")\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred))\n",
    "\n",
    "ada=AdaBoostClassifier(n_estimators=4)\n",
    "ada.fit(X_train,y_train)\n",
    "y_pred=ada.predict(X_test)\n",
    "\n",
    "print(\"AdaBoost with 4 estimators\")\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred))\n",
    "\n",
    "ada=AdaBoostClassifier(n_estimators=10)\n",
    "ada.fit(X_train,y_train)\n",
    "y_pred=ada.predict(X_test)\n",
    "\n",
    "print(\"AdaBoost with 10 estimators\")\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred))\n",
    "\n",
    "#Random Forest\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred))\n"
   ],
   "id": "8ff680dfcc189656",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with 2 estimators\n",
      "F1 Score:  0.5639445300462249\n",
      "AdaBoost with 4 estimators\n",
      "F1 Score:  0.654891304347826\n",
      "AdaBoost with 10 estimators\n",
      "F1 Score:  0.7014341590612777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "F1 Score:  0.9011264080100125\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning\n",
    "### Some of the parameters we can tune are:\n",
    "- n_estimators: The number of weak learners to train iteratively.\n",
    "- learning_rate: It contributes to the weights of weak learners. It uses 1 as a default value.\n",
    "- estimator: The base estimator from which the boosted ensemble is built. The default is a decision tree initialized with max_depth=1.\n",
    "- algorithm: The algorithm to use for the optimization. The posible values are 'SAMME' and 'SAMME.R', the difference is that 'SAMME.R' uses the predicted probabilities to update the additive model, while 'SAMME' uses the predicted class labels.\n",
    "- random_state: The seed used by the random number generator.\n",
    "\n",
    "### Something to take into consideration is the weak learner. By default, AdaBoost uses a decision tree with max_depth=1. We can try to use a different weak learner to see if it improves the performance of AdaBoost. All this parameters will be tuned using GridSearchCV."
   ],
   "id": "82eae66a6e4da1e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:28:04.763977Z",
     "start_time": "2024-11-11T13:24:33.759186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Now we will perform a grid search and we will store the acc and f1 score for each parameter combination to plot them later\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Define the weak learners\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define the weak learners\n",
    "# Define the weak learners\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "svc = SVC(probability=True, kernel='linear')\n",
    "rf = RandomForestClassifier(n_estimators=1)\n",
    "nb=GaussianNB()\n",
    "\n",
    "# Define the parameters to tune for AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [10,50,100,500],\n",
    "    'learning_rate': [ 0.1,0.2,0.3,1],\n",
    "    'estimator': [dt, rf],\n",
    "    'algorithm': [ 'SAMME'],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Use GridSearchCV to tune the parameters for AdaBoost\n",
    "ada = AdaBoostClassifier()\n",
    "grid_search_ada = GridSearchCV(ada, param_grid_ada, cv=5, scoring='f1')\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "print(\"AdaBoost completed\") \n",
    "# Store results for AdaBoost\n",
    "ada_best_params = grid_search_ada.best_params_\n",
    "ada_best_score = grid_search_ada.best_score_\n",
    "\n",
    "# Define the parameters to tune for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [2,10,15,20,100,200],\n",
    "    'max_depth': [2, 3, 4, 5,10, None],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to tune the parameters for Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='f1')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Store results for Random Forest\n",
    "rf_best_params = grid_search_rf.best_params_\n",
    "rf_best_score = grid_search_rf.best_score_\n",
    "\n",
    "# Define the parameters to tune for Naive Bayes\n",
    "param_grid_nb = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-6, 1e-5]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to tune the parameters for Naive Bayes\n",
    "nb = GaussianNB()\n",
    "grid_search_nb = GridSearchCV(nb, param_grid_nb, cv=5, scoring='f1')\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "nb_best_params = grid_search_nb.best_params_\n",
    "nb_best_score = grid_search_nb.best_score_\n",
    "\n",
    "\n",
    "summary_table = pd.DataFrame({\n",
    "    'Algorithm': ['AdaBoost', 'Random Forest', 'Naive Bayes'],\n",
    "    'Best Parameters': [ada_best_params, rf_best_params, nb_best_params],\n",
    "    'Best F1 Score': [ada_best_score, rf_best_score, nb_best_score]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison Summary\")\n",
    "# Set display options\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content in columns\n",
    "pd.set_option('display.max_columns', None)   # Show all columns\n",
    "\n",
    "# Display the DataFrame\n",
    "print(summary_table)"
   ],
   "id": "5d214801572ec787",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost completed\n",
      "Model Comparison Summary\n",
      "       Algorithm  \\\n",
      "0       AdaBoost   \n",
      "1  Random Forest   \n",
      "2    Naive Bayes   \n",
      "\n",
      "                                                                                                                              Best Parameters  \\\n",
      "0  {'algorithm': 'SAMME', 'estimator': RandomForestClassifier(n_estimators=1), 'learning_rate': 0.2, 'n_estimators': 500, 'random_state': 42}   \n",
      "1                                                                                {'max_depth': None, 'n_estimators': 100, 'random_state': 42}   \n",
      "2                                                                                                                    {'var_smoothing': 1e-09}   \n",
      "\n",
      "   Best F1 Score  \n",
      "0       0.888471  \n",
      "1       0.877598  \n",
      "2       0.745947  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### As the previous dataset was too simple, a random forest classifier performed better than AdaBoost, the best AdaBoost hyperparameters was using 1 estimator with random forest. We will now use a more complex dataset to see if AdaBoost performs better than Random Forest and Naive Bayes. This dataset deals with a classification problem, where we will classify whether a client will subscribe to a term deposit or not. The dataset is the bank marketing dataset.\n",
    "\n",
    "\n",
    "# Bank marketing dataset\n",
    "## This dataset contains the following features:\n",
    "   ### bank client data:\n",
    "   - age (numeric)\n",
    "   - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
    "                                       \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n",
    "   - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "   - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "   - default: has credit in default? (binary: \"yes\",\"no\")\n",
    "   - balance: average yearly balance, in euros (numeric) \n",
    "   - housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "   - loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "   #### related with the last contact of the current campaign:\n",
    "   - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
    "   - day: last contact day of the month (numeric)\n",
    "   - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "   - duration: last contact duration, in seconds (numeric)\n",
    "   ### other attributes:\n",
    "   - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "   - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "   - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "   - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "  \n",
    "## We will now read the dataset and preprocessthe features needed for the classification task.\n"
   ],
   "id": "7798b5129b063e5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:28:04.927608Z",
     "start_time": "2024-11-11T13:28:04.822247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "#Read the dataset\n",
    "data=pd.read_csv(\"./bank-full.csv\", sep=\";\")\n",
    "\n",
    "data.head()\n",
    "\n"
   ],
   "id": "d7f3a80332162273",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:28:05.039524Z",
     "start_time": "2024-11-11T13:28:05.008307Z"
    }
   },
   "cell_type": "code",
   "source": "data.info()",
   "id": "c38270583ff7f858",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:28:05.114946Z",
     "start_time": "2024-11-11T13:28:05.086820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#check for missing values\n",
    "\n",
    "data.isnull().sum()"
   ],
   "id": "e980e5e4c36a77d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### We can see there are no missing values in the dataset and that many of the features are categorical. We will need to encode these features to be able to use them in the classification task. We will also encode the target variable.",
   "id": "af6a07ed6eb05e7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e255c6a30fac9a86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:28:05.330832Z",
     "start_time": "2024-11-11T13:28:05.189848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Encode categorical features\n",
    "\n",
    "\n",
    "#get all object features one hot encoding to the columns \"job\", \"marital\" and \"contact\". Perform label encoding for the rest of the object features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#One hot encoding\n",
    "ohe=OneHotEncoder()\n",
    "job_marital_contact=ohe.fit_transform(data[['job','marital','contact']]).toarray()\n",
    "job_marital_contact=pd.DataFrame(job_marital_contact,columns=ohe.get_feature_names_out(['job', 'marital', 'contact']))\n",
    "\n",
    "#Label encoding\n",
    "le=LabelEncoder()\n",
    "data['education']=le.fit_transform(data['education'])\n",
    "data['default']=le.fit_transform(data['default'])\n",
    "data['housing']=le.fit_transform(data['housing'])\n",
    "data['loan']=le.fit_transform(data['loan'])\n",
    "\n",
    "\n",
    "\n",
    "#Concatenate the one hot encoded features with the label encoded features\n",
    "data=pd.concat([data,job_marital_contact],axis=1)\n",
    "\n",
    "#Drop the original columns\n",
    "data.drop(['job','marital','contact'],axis=1,inplace=True)\n",
    "\n",
    "#Encode the target variable\n",
    "data['y']=le.fit_transform(data['y'])\n",
    "\n",
    "#drop the column poutcome as this is the predictions (all are unknown)\n",
    "data.drop('poutcome',axis=1,inplace=True)\n",
    "\n",
    "#Month to numerical\n",
    "data['month']=le.fit_transform(data['month'])\n",
    "\n",
    "#Standarize balance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "data['balance']=scaler.fit_transform(data[['balance']])\n",
    "\n",
    "data.head()\n"
   ],
   "id": "34031d53f032f8eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age  education  default   balance  housing  loan  day  month  duration  \\\n",
       "0   58          2        0  0.256419        1     0    5      8       261   \n",
       "1   44          1        0 -0.437895        1     0    5      8       151   \n",
       "2   33          1        0 -0.446762        1     1    5      8        76   \n",
       "3   47          3        0  0.047205        1     0    5      8        92   \n",
       "4   33          3        0 -0.447091        0     0    5      8       198   \n",
       "\n",
       "   campaign  pdays  previous  y  job_admin.  job_blue-collar  \\\n",
       "0         1     -1         0  0         0.0              0.0   \n",
       "1         1     -1         0  0         0.0              0.0   \n",
       "2         1     -1         0  0         0.0              0.0   \n",
       "3         1     -1         0  0         0.0              1.0   \n",
       "4         1     -1         0  0         0.0              0.0   \n",
       "\n",
       "   job_entrepreneur  job_housemaid  job_management  job_retired  \\\n",
       "0               0.0            0.0             1.0          0.0   \n",
       "1               0.0            0.0             0.0          0.0   \n",
       "2               1.0            0.0             0.0          0.0   \n",
       "3               0.0            0.0             0.0          0.0   \n",
       "4               0.0            0.0             0.0          0.0   \n",
       "\n",
       "   job_self-employed  job_services  job_student  job_technician  \\\n",
       "0                0.0           0.0          0.0             0.0   \n",
       "1                0.0           0.0          0.0             1.0   \n",
       "2                0.0           0.0          0.0             0.0   \n",
       "3                0.0           0.0          0.0             0.0   \n",
       "4                0.0           0.0          0.0             0.0   \n",
       "\n",
       "   job_unemployed  job_unknown  marital_divorced  marital_married  \\\n",
       "0             0.0          0.0               0.0              1.0   \n",
       "1             0.0          0.0               0.0              0.0   \n",
       "2             0.0          0.0               0.0              1.0   \n",
       "3             0.0          0.0               0.0              1.0   \n",
       "4             0.0          1.0               0.0              0.0   \n",
       "\n",
       "   marital_single  contact_cellular  contact_telephone  contact_unknown  \n",
       "0             0.0               0.0                0.0              1.0  \n",
       "1             1.0               0.0                0.0              1.0  \n",
       "2             0.0               0.0                0.0              1.0  \n",
       "3             0.0               0.0                0.0              1.0  \n",
       "4             1.0               0.0                0.0              1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>contact_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256419</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.437895</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.446762</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.447091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### With the preprocessing done, we will now separate the features and the target variable. We will also split the data into training and testing sets.",
   "id": "2d43c1ea8eb0ae29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:28:05.395431Z",
     "start_time": "2024-11-11T13:28:05.373550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now that we have done the preprocessing, we will separate the features and the target variable. We will also split the data into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data.drop('y',axis=1)\n",
    "y=data['y']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n"
   ],
   "id": "f7cca4efb9c4dd1b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T13:28:12.016905Z",
     "start_time": "2024-11-11T13:28:05.698824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we will perform a simple comparison between base random forest, naive bayes and adaboost classifiers\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "nb=GaussianNB()\n",
    "ada=AdaBoostClassifier()\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "nb.fit(X_train,y_train)\n",
    "ada.fit(X_train,y_train)\n",
    "\n",
    "y_pred_rf=rf.predict(X_test)\n",
    "y_pred_nb=nb.predict(X_test)\n",
    "y_pred_ada=ada.predict(X_test)\n",
    "\n",
    "#compare f1-score and accuracy\n",
    "print(\"Random Forest\")\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred_rf))\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred_rf))\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred_nb))\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred_nb))\n",
    "\n",
    "print(\"AdaBoost\")\n",
    "print(\"F1 Score: \",f1_score(y_test,y_pred_ada))\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred_ada))"
   ],
   "id": "9b2cfb50c2382af1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alvar\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "F1 Score:  0.48574686431014824\n",
      "Accuracy:  0.9002543403737697\n",
      "Naive Bayes\n",
      "F1 Score:  0.4113785557986871\n",
      "Accuracy:  0.8215194072763463\n",
      "AdaBoost\n",
      "F1 Score:  0.42473745624270715\n",
      "Accuracy:  0.8909653875926131\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### We can see that Random Forest performs better than AdaBoost and Naive Bayes with base params. We will now tune the hyperparameters of AdaBoost to see if we can improve its performance.",
   "id": "95e36afa707298b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T15:11:16.912200Z",
     "start_time": "2024-11-11T13:28:12.130424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define weak learners\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "dt2 = DecisionTreeClassifier(max_depth=2)\n",
    "dt3 = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "svc = SVC(probability=True, kernel='linear')\n",
    "rf = RandomForestClassifier(n_estimators=1, max_depth=1)\n",
    "rf2 = RandomForestClassifier(n_estimators=2, max_depth=2)\n",
    "rf3 = RandomForestClassifier(n_estimators=4, max_depth=4)\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Define the parameter grid for AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [250, 500, 1000],\n",
    "    'learning_rate': [0.05, 0.1, 0.5, 1.0],\n",
    "    'estimator': [dt, dt2, dt3, rf, rf2, rf3, nb],\n",
    "    'algorithm': ['SAMME'],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Timing and grid search for AdaBoost\n",
    "start_time = time.time()\n",
    "ada = AdaBoostClassifier()\n",
    "grid_search_ada = GridSearchCV(ada, param_grid_ada, cv=5, scoring='f1', verbose=3)\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "ada_time_grid = end_time - start_time\n",
    "print(\"AdaBoost completed\")\n",
    "\n",
    "# Store results for AdaBoost\n",
    "ada_best_params = grid_search_ada.best_params_\n",
    "ada_best_score = grid_search_ada.best_score_\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [2, 10, 15, 20, 100, 200],\n",
    "    'max_depth': [2, 3, 4, 5, 10, None],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Timing and grid search for Random Forest\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier()\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='f1')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "rf_time_grid = end_time - start_time\n",
    "\n",
    "# Store results for Random Forest\n",
    "rf_best_params = grid_search_rf.best_params_\n",
    "rf_best_score = grid_search_rf.best_score_\n",
    "\n",
    "# Define the parameter grid for Naive Bayes\n",
    "param_grid_nb = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-6, 1e-5]\n",
    "}\n",
    "\n",
    "# Timing and grid search for Naive Bayes\n",
    "start_time = time.time()\n",
    "nb = GaussianNB()\n",
    "grid_search_nb = GridSearchCV(nb, param_grid_nb, cv=5, scoring='f1')\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "nb_time_grid = end_time - start_time\n",
    "\n",
    "# Store results for Naive Bayes\n",
    "nb_best_params = grid_search_nb.best_params_\n",
    "nb_best_score = grid_search_nb.best_score_\n",
    "\n",
    "# Create a summary table including the time taken\n",
    "summary_table = pd.DataFrame({\n",
    "    'Algorithm': ['AdaBoost', 'Random Forest', 'Naive Bayes'],\n",
    "    'Best Parameters': [ada_best_params, rf_best_params, nb_best_params],\n",
    "    'Best F1 Score': [ada_best_score, rf_best_score, nb_best_score],\n",
    "    'Grid Search Time (seconds)': [ada_time_grid, rf_time_grid, nb_time_grid]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison Summary\")\n",
    "# Display the summary table\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(summary_table)\n"
   ],
   "id": "5998e5c71f7e94a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.301 total time=  13.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.335 total time=  13.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.357 total time=  13.5s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.363 total time=  10.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.365 total time=   9.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.360 total time=  18.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.348 total time=  18.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.384 total time=  18.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.382 total time=  18.3s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.399 total time=  18.4s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.380 total time=  36.9s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.401 total time=  36.4s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.426 total time=  46.5s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.402 total time=  46.7s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.442 total time=  41.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.366 total time=   8.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.377 total time=   8.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.386 total time=   8.3s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.378 total time=   8.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.429 total time=   8.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.383 total time=  16.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.417 total time=  16.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.419 total time=  16.3s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.412 total time=  16.8s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.431 total time=  19.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.401 total time=  50.4s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.421 total time=  50.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.429 total time=  49.6s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.431 total time=  50.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.459 total time=  50.5s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.429 total time=  12.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.467 total time=  12.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.446 total time=  11.9s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.468 total time=  12.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.498 total time=  11.8s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.452 total time=  24.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.475 total time=  24.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.453 total time=  24.4s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.471 total time=  24.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.511 total time=  24.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.457 total time=  48.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.476 total time=  48.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.459 total time=  47.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.477 total time=  47.9s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.504 total time=  51.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.470 total time=  12.7s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.486 total time=  12.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.517 total time=  12.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.487 total time=  12.0s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.521 total time=  11.8s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.467 total time=  24.0s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.487 total time=  24.1s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.492 total time=  24.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.489 total time=  24.3s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.523 total time=  20.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.491 total time=  34.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.491 total time=  37.6s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.496 total time=  34.4s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.508 total time=  35.5s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.529 total time=  37.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.235 total time=   6.4s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.263 total time=   6.1s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.294 total time=   6.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.288 total time=   6.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.314 total time=   6.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.292 total time=  12.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.326 total time=  12.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.317 total time=  12.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.352 total time=  12.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.372 total time=  12.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.345 total time=  26.0s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.357 total time=  25.7s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.348 total time=  25.0s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.366 total time=  25.0s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.429 total time=  25.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.303 total time=   6.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.326 total time=   6.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.322 total time=   6.3s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.359 total time=   6.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.374 total time=   6.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.363 total time=  12.4s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.353 total time=  12.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.353 total time=  13.8s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.394 total time=  12.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.418 total time=  12.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.377 total time=  25.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.382 total time=  25.9s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.385 total time=  26.0s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.415 total time=  27.8s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.456 total time=  26.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.412 total time=   6.7s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.414 total time=   6.6s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.438 total time=   6.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.457 total time=   6.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.491 total time=   6.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.413 total time=  12.7s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.440 total time=  13.1s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.440 total time=  13.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.462 total time=  13.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.488 total time=  13.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.434 total time=  26.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.444 total time=  25.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.447 total time=  27.9s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.473 total time=  22.3s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.501 total time=  26.6s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.431 total time=   6.8s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.475 total time=   7.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.452 total time=   6.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.454 total time=   6.0s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.493 total time=   6.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.440 total time=  12.0s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.473 total time=  12.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.457 total time=  12.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.484 total time=  12.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.501 total time=  12.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.440 total time=  24.0s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.474 total time=  24.1s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.464 total time=  24.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.471 total time=  24.0s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.504 total time=  24.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.378 total time=  10.8s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.393 total time=  10.7s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.402 total time=  10.6s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.412 total time=  10.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.447 total time=  10.6s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.394 total time=  21.7s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.427 total time=  23.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.435 total time=  22.9s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.438 total time=  22.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.463 total time=  22.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.424 total time=  47.0s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.461 total time=  47.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.455 total time=  43.3s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.454 total time=  45.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.484 total time=  47.6s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.408 total time=  11.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.414 total time=  11.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.432 total time=  11.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.437 total time=  11.8s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.477 total time=  11.6s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.427 total time=  23.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.444 total time=  23.4s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.451 total time=  25.4s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.453 total time=  24.0s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.490 total time=  22.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.434 total time=  44.4s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.455 total time=  46.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.455 total time=  45.9s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.472 total time=  45.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.494 total time=  44.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.464 total time=  10.7s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.503 total time=  11.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.487 total time=  11.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.488 total time=  11.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.510 total time=  11.6s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.482 total time=  23.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.502 total time=  22.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.493 total time=  23.0s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.486 total time=  22.9s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.506 total time=  21.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.484 total time=  42.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.506 total time=  42.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.512 total time=  41.8s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.496 total time=  41.9s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.503 total time=  42.4s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.496 total time=  10.7s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.522 total time=  10.7s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.508 total time=  10.8s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.494 total time=  10.9s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.515 total time=  10.5s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.489 total time=  21.0s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.516 total time=  21.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.511 total time=  20.9s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.495 total time=  21.0s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.511 total time=  20.9s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.502 total time=  42.8s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.531 total time=  42.1s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.513 total time=  41.9s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.495 total time=  41.9s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.534 total time=  42.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.102 total time=   2.4s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.087 total time=   2.4s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.106 total time=   2.4s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.092 total time=   2.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.089 total time=   2.4s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.191 total time=   4.5s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.193 total time=   4.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.169 total time=   3.8s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.178 total time=   4.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.187 total time=   4.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.191 total time=   4.5s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.193 total time=   4.5s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.169 total time=   3.7s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.178 total time=   4.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.187 total time=   4.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.171 total time=   1.9s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.210 total time=   2.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.157 total time=   1.5s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.212 total time=   2.3s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.227 total time=   2.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.171 total time=   1.9s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.210 total time=   2.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.157 total time=   1.5s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.266 total time=   3.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.279 total time=   3.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.171 total time=   1.9s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.210 total time=   2.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.157 total time=   1.5s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.266 total time=   3.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.279 total time=   3.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.324 total time=   0.9s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.338 total time=   1.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.320 total time=   0.6s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.310 total time=   0.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.388 total time=   1.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.324 total time=   0.9s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.338 total time=   1.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.320 total time=   0.6s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.310 total time=   0.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.388 total time=   1.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.324 total time=   1.0s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.338 total time=   1.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.320 total time=   0.6s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.310 total time=   0.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.388 total time=   1.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.340 total time=   0.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.367 total time=   0.6s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.372 total time=   0.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.392 total time=   0.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.441 total time=   0.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.340 total time=   0.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.367 total time=   0.6s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.372 total time=   0.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.392 total time=   0.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.441 total time=   0.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.340 total time=   0.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.367 total time=   0.6s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.372 total time=   0.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.392 total time=   0.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=1, n_estimators=1), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.441 total time=   0.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.315 total time=   3.9s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.326 total time=   3.9s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.332 total time=   3.9s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.333 total time=   3.9s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.371 total time=   4.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.384 total time=   8.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.389 total time=   8.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.390 total time=   8.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.404 total time=   8.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.425 total time=   6.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.384 total time=   8.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.393 total time=   9.5s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.409 total time=  11.6s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.424 total time=  13.3s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.425 total time=   7.4s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.386 total time=   4.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.395 total time=   4.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.369 total time=   4.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.405 total time=   4.5s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.421 total time=   4.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.414 total time=   7.0s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.429 total time=   8.4s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.413 total time=   8.0s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.427 total time=   5.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.470 total time=   8.6s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.414 total time=   6.5s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.429 total time=   8.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.428 total time=  10.5s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.427 total time=   4.9s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.473 total time=   9.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.431 total time=   2.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.429 total time=   2.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.439 total time=   4.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.450 total time=   3.9s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.483 total time=   4.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.431 total time=   2.9s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.429 total time=   2.4s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.436 total time=   4.5s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.450 total time=   4.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.500 total time=   4.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.431 total time=   2.8s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.429 total time=   2.1s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.436 total time=   4.4s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.450 total time=   4.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.500 total time=   5.0s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.385 total time=   0.7s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.449 total time=   2.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.476 total time=   3.6s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.445 total time=   2.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.477 total time=   1.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.385 total time=   0.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.449 total time=   2.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.476 total time=   4.0s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.445 total time=   2.2s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.477 total time=   1.4s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.385 total time=   0.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.449 total time=   2.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.476 total time=   4.0s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.445 total time=   2.0s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=2, n_estimators=2), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.477 total time=   1.2s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.442 total time=   9.4s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.464 total time=  10.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.460 total time=   9.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.458 total time=  10.3s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.486 total time=   9.9s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.471 total time=  19.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.492 total time=  18.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.470 total time=  19.5s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.492 total time=  18.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.506 total time=  20.4s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.493 total time=  38.1s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.517 total time=  39.9s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.485 total time=  39.9s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.506 total time=  40.5s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.518 total time=  42.8s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.459 total time=   9.8s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.488 total time=   9.9s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.471 total time=   9.8s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.486 total time=  10.3s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.509 total time=   9.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.479 total time=  18.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.498 total time=  18.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.485 total time=  18.4s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.511 total time=  18.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.524 total time=  18.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.491 total time=  36.7s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.524 total time=  36.6s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.499 total time=  36.6s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.516 total time=  36.8s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.525 total time=  36.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.496 total time=   9.2s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.521 total time=   9.1s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.511 total time=   9.1s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.516 total time=   9.3s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.507 total time=   9.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.493 total time=  18.4s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.527 total time=  18.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.539 total time=  17.3s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.524 total time=  17.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.528 total time=  17.4s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.499 total time=  36.0s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.532 total time=  36.6s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.528 total time=  34.8s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.513 total time=  34.7s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.518 total time=  29.1s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.482 total time=   8.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.468 total time=   8.6s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.501 total time=   8.6s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.503 total time=   8.7s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.501 total time=   8.6s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.486 total time=  17.4s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.491 total time=  17.4s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.500 total time=  17.4s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.510 total time=  17.5s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.520 total time=  17.4s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.500 total time=  35.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.475 total time=  34.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.500 total time=  34.8s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.506 total time=  35.0s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=RandomForestClassifier(max_depth=4, n_estimators=4), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.510 total time=  41.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.434 total time=  11.5s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.441 total time=  10.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.452 total time=  10.4s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.440 total time=  10.8s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=250, random_state=42;, score=0.463 total time=  11.8s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.434 total time=  11.5s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.441 total time=   9.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.452 total time=  10.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.440 total time=  10.6s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=500, random_state=42;, score=0.463 total time=  23.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.434 total time=  11.4s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.441 total time=  10.0s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.452 total time=  10.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.440 total time=  11.1s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.05, n_estimators=1000, random_state=42;, score=0.463 total time=  46.5s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.434 total time=   4.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.436 total time=   4.6s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.447 total time=   5.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.442 total time=   5.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=250, random_state=42;, score=0.457 total time=   5.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.434 total time=   4.7s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.436 total time=   4.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.447 total time=   5.5s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.442 total time=   5.5s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=500, random_state=42;, score=0.457 total time=   5.7s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.434 total time=   4.6s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.436 total time=   4.8s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.447 total time=   5.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.442 total time=   5.4s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.1, n_estimators=1000, random_state=42;, score=0.457 total time=   5.6s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.427 total time=   0.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.404 total time=   0.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.434 total time=   0.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.428 total time=   0.8s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=250, random_state=42;, score=0.480 total time=   0.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.427 total time=   0.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.404 total time=   0.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.434 total time=   0.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.428 total time=   0.8s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=500, random_state=42;, score=0.480 total time=   0.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.427 total time=   0.3s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.404 total time=   0.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.434 total time=   0.2s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.428 total time=   0.8s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=0.5, n_estimators=1000, random_state=42;, score=0.480 total time=   0.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.361 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.338 total time=   0.3s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.420 total time=   0.4s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.385 total time=   0.5s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=250, random_state=42;, score=0.425 total time=   0.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.361 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.338 total time=   0.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.420 total time=   0.3s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.385 total time=   0.5s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=500, random_state=42;, score=0.425 total time=   0.3s\n",
      "[CV 1/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.361 total time=   0.1s\n",
      "[CV 2/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.338 total time=   0.2s\n",
      "[CV 3/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.420 total time=   0.3s\n",
      "[CV 4/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.385 total time=   0.5s\n",
      "[CV 5/5] END algorithm=SAMME, estimator=GaussianNB(), learning_rate=1.0, n_estimators=1000, random_state=42;, score=0.425 total time=   0.3s\n",
      "AdaBoost completed\n",
      "Model Comparison Summary\n",
      "       Algorithm  \\\n",
      "0       AdaBoost   \n",
      "1  Random Forest   \n",
      "2    Naive Bayes   \n",
      "\n",
      "                                                                                                                                           Best Parameters  \\\n",
      "0  {'algorithm': 'SAMME', 'estimator': RandomForestClassifier(max_depth=4, n_estimators=4), 'learning_rate': 0.5, 'n_estimators': 500, 'random_state': 42}   \n",
      "1                                                                                             {'max_depth': None, 'n_estimators': 200, 'random_state': 42}   \n",
      "2                                                                                                                                 {'var_smoothing': 1e-06}   \n",
      "\n",
      "   Best F1 Score  Grid Search Time (seconds)  \n",
      "0       0.522249                 6011.138658  \n",
      "1       0.454046                  172.871583  \n",
      "2       0.440348                    0.747000  \n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  Now we will plot the f1 score and accuracy and the ROC curves of the best models",
   "id": "20490f079b2ccbd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T15:11:18.102547Z",
     "start_time": "2024-11-11T15:11:16.965373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot the f1 score and accuracy\n",
    "f1_scores=[rf_best_score, nb_best_score, ada_best_score]\n",
    "accuracies=[accuracy_score(y_test,y_pred_rf),accuracy_score(y_test,y_pred_nb),accuracy_score(y_test,y_pred_ada)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(['Random Forest','Naive Bayes','AdaBoost'],f1_scores)\n",
    "plt.ylim(0.4, 0.6) \n",
    "plt.title(\"F1 Score\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(['Random Forest','Naive Bayes','AdaBoost'],accuracies)\n",
    "plt.ylim(0.3, 1) \n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "8cba0202a34b18ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ccce2d3b29673a06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T15:11:20.365183Z",
     "start_time": "2024-11-11T15:11:18.201010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Plot the ROC curves\n",
    "# Retrieve the best models from each grid search\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_nb = grid_search_nb.best_estimator_\n",
    "best_ada = grid_search_ada.best_estimator_\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_rf = best_rf.predict_proba(X_test)\n",
    "y_pred_nb = best_nb.predict_proba(X_test)\n",
    "y_pred_ada = best_ada.predict_proba(X_test)\n",
    "\n",
    "# Compute ROC curves\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf[:, 1])\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, y_pred_nb[:, 1])\n",
    "fpr_ada, tpr_ada, _ = roc_curve(y_test, y_pred_ada[:, 1])\n",
    "\n",
    "# Compute AUC scores\n",
    "auc_rf = roc_auc_score(y_test, y_pred_rf[:, 1])\n",
    "auc_nb = roc_auc_score(y_test, y_pred_nb[:, 1])\n",
    "auc_ada = roc_auc_score(y_test, y_pred_ada[:, 1])\n",
    "\n",
    "# Plot the ROC curves with AUC values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(fpr_rf, tpr_rf, label=f\"Random Forest (AUC = {auc_rf:.2f})\")\n",
    "plt.plot(fpr_nb, tpr_nb, label=f\"Naive Bayes (AUC = {auc_nb:.2f})\")\n",
    "plt.plot(fpr_ada, tpr_ada, label=f\"AdaBoost (AUC = {auc_ada:.2f})\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve with AUC Values\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "ed2294e20cd5233d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHUCAYAAAANwniNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACou0lEQVR4nOzdd3hU1brH8e9k0iuEkAABQu8dpIqK0rFiwYZIU2wcxC5HEfWIeixc9YBKFUXEgl1QQFAQkCIICtI7CZAe0jOz7h8DE4YkkECSSfl9nmfurL3K3u+EHO+8WWuvbTHGGERERERERKRAHu4OQEREREREpKxT4iQiIiIiInIeSpxERERERETOQ4mTiIiIiIjIeShxEhEREREROQ8lTiIiIiIiIuehxElEREREROQ8lDiJiIiIiIichxInERERERGR81DiJCJSRHPmzMFisThfnp6e1KxZk1tvvZVdu3blOyY7O5tp06bRrVs3QkJC8PPzo3nz5jz55JPExcXlO8Zut/Phhx/Su3dvwsLC8PLyIjw8nKuvvppvv/0Wu91+3lgzMzN55513uPTSS6latSre3t5ERkZyyy238Msvv1zUz6G8qVevHnfffbfz+OjRozz33HNs3rw5T9+7776bwMDAYrluhw4dsFgsvPbaa/m2P/fcc1gsFmJjY/Ntb9WqFVdccUWe+mPHjvHkk0/SunVrAgMD8fX1pXHjxvzrX/8q8PcQ4OGHH8ZisfDPP/8U2GfChAlYLBb++OOPc3+4M5z98xURqWiUOImIXKDZs2ezZs0ali5dyoMPPsg333zDpZdeSkJCgku/tLQ0+vTpw0MPPUT79u2ZP38+P/zwA0OHDuX999+nffv27Nixw2VMRkYGAwcOZNiwYYSHhzNt2jR+/vln3n33XWrVqsXNN9/Mt99+e874YmNj6dGjB+PHj6dVq1bMmTOHZcuW8frrr2O1Wrnqqqv4888/i/3nUlZ9+eWXPPPMM87jo0ePMmnSpHwTp+KyefNmNm3aBMDMmTOL7bzr1q2jdevWzJw5k5tuuomFCxeyePFiHn30Uf744w86d+5c4NiRI0cCMGvWrHzb7XY7c+fOpV27dnTo0KHYYhYRKfeMiIgUyezZsw1g1q9f71I/adIkA5hZs2a51N9zzz0GMJ988kmec+3YscOEhISYli1bmpycHGf9fffdZwDzwQcf5BvDzp07zZ9//nnOOAcMGGA8PT3NsmXL8m1ft26dOXDgwDnPUVhpaWnFcp7StH79egOY2bNn52kbNmyYCQgIuOhrPPDAAwYwgwYNMoD57bff8vSZOHGiAcyJEyfyPUfLli3N5Zdf7jxOSkoyNWrUMHXq1DGHDh3Kd8xnn312zrg6d+5satSoYbKzs/O0LVq0yADm7bffPuc5zhYVFWWGDRtWpDEiIuWJZpxERIpJp06dAMcSqtNiYmKYNWsW/fr1Y8iQIXnGNGnShCeeeIK///6br776yjlmxowZ9OvXj7vuuivfazVu3Jg2bdoUGMvGjRtZtGgRI0eO5Morr8y3zyWXXELdunWB3OViZzu9LHH//v3Ounr16nH11VezcOFC2rdvj6+vL5MmTaJ9+/b07NkzzzlsNhuRkZEMHjzYWZeVlcWLL75Is2bN8PHxoXr16gwfPpwTJ04U+JkAvv/+eywWC+vXr3fWffHFF1gsFgYNGuTSt02bNtx4440ucZ9eSrZixQouueQSAIYPH+5cdvncc8+5nGP37t0MHDiQwMBA6tSpwyOPPEJmZuY5YzwtIyODjz/+mI4dO/Lmm28CBc/yFMX06dOJiYnh1VdfpXbt2vn2uemmm855jpEjRxITE8OiRYvytM2ePRsfHx/uuOMOMjIyeOSRR2jXrh0hISGEhobSrVs3vv766/PGmd/vDjh+9haLhRUrVrjUL126lKuuuorg4GD8/f3p0aMHy5Ytc+lz4sQJ7rnnHurUqeP8venRowdLly49bzwiIhdLiZOISDHZt28f4EiGTlu+fDk5OTlcf/31BY473bZkyRLnmOzs7HOOOZ+ffvrJ5dzF7Y8//uCxxx5j7NixLF68mBtvvJHhw4ezatWqPPfX/PTTTxw9epThw4cDjqVg1113HS+//DK3334733//PS+//DJLlizhiiuuID09vcDrXn755Xh5ebl8UV66dCl+fn788ssvZGdnA3D8+HH++usvevfune95OnTowOzZswH497//zZo1a1izZg2jRo1y9snOzubaa6/lqquu4uuvv2bEiBG8+eabvPLKK4X6GS1cuJCEhARGjBhB48aNufTSS1mwYAEnT54s1PiC/PTTT1itVq655poLPsdtt92Gv79/nkQuISGBr7/+mhtuuIGqVauSmZlJfHw8jz76KF999RXz58/n0ksvZfDgwcydO/eiPseZPvroI/r27UtwcDAffPABn376KaGhofTr188leRo6dChfffUVzz77LD/99BMzZsygd+/eBd4nKCJSrNw95SUiUt6cXqq3du1ak52dbVJSUszixYtNjRo1zGWXXeay/Onll182gFm8eHGB50tPTzeAGTBgQKHHnM+YMWMMYP75559C9T+9XOxspz/rvn37nHVRUVHGarWaHTt2uPSNjY013t7e5umnn3apv+WWW0xERITz5zJ//nwDmC+++MKl3+mlc1OnTj1nrJdeeqm58sornceNGjUyjz32mPHw8DC//PKLMcaYefPmGcDs3LnTJe4zl5Kdb6keYD799FOX+oEDB5qmTZueM77TrrzySuPr62sSEhKMMbk/y5kzZ7r0K+pSvWbNmpkaNWoUKoZzGTZsmPHy8jLHjh1z1r399tsGMEuWLMl3TE5OjsnOzjYjR4407du3d2k7++eb3++OMcYsX77cAGb58uXGGGNSU1NNaGioueaaa1z62Ww207ZtW9O5c2dnXWBgoBk3btwFfFoRkYunGScRkQvUtWtXvLy8CAoKon///lStWpWvv/4aT0/PCzpffkvlyqo2bdq4zKwBVKtWjWuuuYYPPvjAuePf6RmMu+66y/lz+e6776hSpQrXXHMNOTk5zle7du2oUaNGniVcZ7vqqqv47bffSE9P58CBA+zevZtbb72Vdu3aOWftli5dSt26dWncuPEFf0aLxZJnVqdNmzYcOHDgvGP37dvH8uXLGTx4MFWqVAHg5ptvJigoqFiW6xWHkSNHkp2dzYcffuismz17NlFRUVx11VXOus8++4wePXoQGBiIp6cnXl5ezJw5k+3btxdLHKtXryY+Pp5hw4a5/D7Y7Xb69+/P+vXrSU1NBaBz587MmTOHF198kbVr1zpnGEVESoMSJxGRCzR37lzWr1/Pzz//zL333sv27du57bbbXPqcvofo9DK+/Jxuq1OnTqHHnE9xnONcatasmW/9iBEjOHLkiDOBmT9/PpmZmS7bVB87dozExES8vb3x8vJyecXExBS4LfdpvXv3JjMzk1WrVrFkyRLCwsJo3749vXv3di7hW7ZsWYHL9ArL398fX19flzofHx8yMjLOO3bWrFkYY7jppptITEwkMTHRufTvt99+c9kK/HRCabPZ8j1XTk4OXl5ezuO6dety4sQJZzJxoXr27EmTJk2cSxa3bNnCH3/84bznCxzLDW+55RYiIyP56KOPWLNmDevXr2fEiBGF+jkUxul7Am+66aY8vw+vvPIKxhji4+MBWLBgAcOGDWPGjBl069aN0NBQ7rrrLmJiYoolFhGRc7mwP4uKiAjNmzd3bgjRq1cvbDYbM2bM4PPPP3fenN+rVy88PT356quvGDNmTL7nOb0pRJ8+fZxjvLy8zjnmfPr168fTTz/NV199Rf/+/c/b/3SCkJmZiY+Pj7O+oCSmoNmxfv36UatWLWbPnk2/fv2YPXs2Xbp0oUWLFs4+YWFhVKtWjcWLF+d7jqCgoHPG2qVLFwIDA1m6dCn79+/nqquuwmKxcNVVV/H666+zfv16Dh48eNGJ04Wy2+3MmTMHwGVDjDPNmjWLV199FYCIiAgAjhw54iyfZowhOjra+XsGjp/xTz/9xLfffsutt956UbGOGDGCJ598knXr1vHxxx/j4eHhkuR+9NFH1K9fnwULFrj8mxdmg4wzf6fOdPbvVFhYGABvv/02Xbt2zfdcp38uYWFhTJkyhSlTpnDw4EG++eYbnnzySY4fP17g75OISHHRjJOISDF59dVXqVq1Ks8++6xzqVqNGjUYMWIEP/74IwsWLMgzZufOnbzyyiu0bNnSuZFDjRo1GDVqFD/++GOBN+Dv2bOHLVu2FBhLhw4dGDBgADNnzuTnn3/Ot8+GDRs4ePAg4NhxDshzzvM9K+psVqvVeQP/ypUr2bBhAyNGjHDpc/XVVxMXF4fNZqNTp055Xk2bNj3nNby8vLjssstYsmQJP//8szPh7NmzJ56envz73/92JlLncjpBPNdmFBfixx9/5PDhwzzwwAMsX748z6tly5bMnTuXnJwcAK688kosFku+vx+LFy8mOTnZJQkcOXIkNWrU4PHHH+fIkSP5xrBw4cJCxTps2DA8PT157733mDdvHldddRVRUVHOdovFgre3t0vSFBMTU6hd9Qr6nfrmm29cjnv06EGVKlXYtm1bvr8PnTp1wtvbO8/569aty4MPPkifPn2K9KBeEZEL5uZ7rEREyp2CnuNkjDGvvvqqAcyHH37orDt58qS5/PLLjaenp7n//vvNokWLzM8//2xeeuklExoaamrXrp1nE4f09HTTr18/Y7FYzO23324+++wz8+uvv5qFCxea++67z/j6+pqvvvrqnHGeOHHCdOzY0Xh7e5sxY8aYr7/+2vz6669mwYIF5s477zRWq9Vs3rzZGON4NlBoaKhp3bq1+fLLL823335rbrzxRlO/fv18N4cYNGhQgdfdsWOHAUzt2rWNn5+fSUxMdGnPyckxAwYMMKGhoWbSpElm0aJFZunSpWbOnDlm2LBhZuHChef8XMYY8/rrrxvAAGb//v3O+l69ehnAtGnTJs+YszcvSE1NNX5+fqZHjx5m+fLlZv369ebIkSPGmIKf41TQJhpnuvHGG42np6fzXGd76623DODy7/fQQw8Zi8Vi7rnnHvPVV1+ZH3/80bz44osmMDDQdOrUyWRmZrqc4/fffzfVq1c31atXN5MmTTI//fSTWbFihZk+fbq5/PLLTZUqVc4Z45muvfZaY7FY8n3W2KxZswxg7rvvPrNs2TIzZ84c07BhQ9O4ceM8P4ezf745OTmmadOmpm7duubjjz82ixYtMvfcc4/zd+r05hDGGPPhhx8aDw8PM2TIEPPZZ5+ZX375xXz++efmmWeeMWPGjDHGGJOYmGjat29v/vvf/5pvv/3WrFixwvz3v/81vr6+5vbbby/05xURuVBKnEREiuhciVN6erqpW7euady4scsDbbOyssz//vc/06VLFxMYGGh8fHxM06ZNzeOPP25iY2PzvU5OTo754IMPzJVXXmlCQ0ONp6enqV69uhkwYID5+OOPjc1mO2+s6enp5q233jLdunUzwcHBxtPT09SqVcsMHjzYfP/99y59161bZ7p3724CAgJMZGSkmThxopkxY0aREydjjOnevbsBzB133JFve3Z2tnnttddM27Ztja+vrwkMDDTNmjUz9957r9m1a9d5P9eff/5pANO4cWOX+v/85z8GMOPHj88zJr8HtM6fP980a9bMeHl5GcBMnDjRGHPhidOJEyeMt7e3uf766wvsk5CQYPz8/Fx2kbPb7WbatGmmU6dOxt/f33h7e5vGjRubJ554wqSkpOR7npiYGPPEE0+Yli1bGn9/f+Pj42MaNWpk7r33XrN169YCr3+2r7/+2gAmNDTUZGRk5Gl/+eWXTb169YyPj49p3ry5mT59er4/h/x+vjt37jR9+/Y1wcHBpnr16uahhx4y33//fZ7EyRhjfvnlFzNo0CATGhpqvLy8TGRkpBk0aJDzYb4ZGRlmzJgxpk2bNiY4ONj4+fmZpk2bmokTJ5rU1NRCf14RkQtlMcaYUpzgEhERERERKXd0j5OIiIiIiMh5KHESERERERE5DyVOIiIiIiIi56HESURERERE5DyUOImIiIiIiJyHEicREREREZHz8HR3AKXNbrdz9OhRgoKCXJ6ELiIiIiIilYsxhpSUFGrVqoWHx7nnlCpd4nT06FHq1Knj7jBERERERKSMOHToELVr1z5nn0qXOAUFBQGOH05wcLCboxEREREREXdJTk6mTp06zhzhXCpd4nR6eV5wcLASJxERERERKdQtPNocQkRERERE5DyUOImIiIiIiJyHEicREREREZHzUOIkIiIiIiJyHkqcREREREREzkOJk4iIiIiIyHkocRIRERERETkPJU4iIiIiIiLnocRJRERERETkPJQ4iYiIiIiInIdbE6dff/2Va665hlq1amGxWPjqq6/OO+aXX36hY8eO+Pr60qBBA959992SD1RERERERCo1tyZOqamptG3blnfeeadQ/fft28fAgQPp2bMnmzZt4umnn2bs2LF88cUXJRypiIiIiIhUZp7uvPiAAQMYMGBAofu/++671K1blylTpgDQvHlzNmzYwGuvvcaNN95YQlGKiIiIiEhl59bEqajWrFlD3759Xer69evHzJkzyc7OxsvLK8+YzMxMMjMzncfJycklHqeIiIiIMQab3WA3YD9VthmD/VSdo8043+12sJ15fLp8Rr1xOY+j3n7qnLnjICUricSsE9jsjmubM2KwkxuDMThjMsZgO9Xv1AdwvOFy6FJ2tjnfXRvMWQOMyXs+xxjDkaz1Z/38zvp5nlEquM21wpxV4fIZzjHmqO0XPC3+WLDk7VdQgPmd8zxMgQfn6Xu+AXk+fxFjKUKHM6u9TSYBJhWDxVnnb9KwYFzqThvfdiJXdr6pCFG6V7lKnGJiYoiIiHCpi4iIICcnh9jYWGrWrJlnzOTJk5k0aVJphSgiIlKp2e2GbLudbJshx2YnOTONXQm7sNnt5NgNOTZDjkvZ8WU+22bHZjen6u3OekcZcmx2bHY72Xaw2+3YjCMxsRvHNe0YzKlE4nQCYLPncMK+Howndhzf2O2nvnSbU+MNp94N2Dmz3s5J32VYbdXP+H5sOKPo8oXR0ccU+YtzSbBYU7FYM9wdRrmXaeJL94J584qyca4iyAZS823JP6DUjKQSjKb4lavECcBicf3Bm1P/NTu7/rSnnnqK8ePHO4+Tk5OpU6dOyQUoIiJSDIwxZNscCUWOzZBls5Njt5OdczoxOaOc40g0smy55Wyb3Tn+zHKOzU7WGeX8+rhc81Rdmj2GDOLJsTlmO04nQI7Zjwzs/luxW9LwDNqGPTvY+Tk8vMrQSg/LWe+FYLOeKKlTlwpPk/tv4fpVyZIn1gK+ShVaoYafo5Pd2LCTQwPfy3Kjs5xjiMXlLf9LnPWhzvWZLWeVDDYaB/Q4o+9Z5zrj+nnazupkOWvM2eNdx7o25I49I8Kz2/J+CJcxFvJ+vjzXt+RttwB+qYfxzE7BMyeVkLg/8cpMIDjhL84lPaA2qVWaOs/mYUsnKaIrxiN3dZgF6Ni89znPU9aUq8SpRo0axMTEuNQdP34cT09PqlWrlu8YHx8ffHx8SiM8ERFxI2MM2+K2EZcRd1ZD7jKnHLvBdmoG4/QMiLPefqre5lrvTA6c40/VmdxZkN3pv+JhvJ1Lsk4vlzLO5VZnzI6c2X5qyVW23zowXmCseZYWuZUF8ASLz/lnLzzI3XEqv2TJ2AKw2H1OfVmznPWl81QdZ3yZs1hcvmxaThXy/QJ65v89q95GDhY8aB58qSO+U+fwsDhiOH0dxzUseJz6huk4j6GKdzWaVmmDxQIeFsc4x1jHu9XD0dd6us7D4vhZeDjO7cGpOg+wnsoCrB659SWpebXm+Fj1HahcSIuHwxtK95pbPwNP73P32fTR+c/j6QeXjHSUfYLh8scvPgsvo8pV4tStWze+/fZbl7qffvqJTp065Xt/k4iIlG02uyE5PZvE9GwS07JITM8mKS23nJCaSXTaQRJyDhFn30KOycAYCzaTTYp1E5gz/t+YJcd9H+R8CrOHrSXL8VaykVy0mv5RWE4lPmf+pT3TlkE13zDah3egdVgb6gRH4unhgdXDQq3AWgR7B5/7xCIlzW4/f5+/F8LfX4Kn78VdKy0O9i6Hwiautszz93G36s0gMwVCG0BkB2h2NdTp7O6oSpVbE6eTJ0+ye/du5/G+ffvYvHkzoaGh1K1bl6eeeoojR44wd+5cAMaMGcM777zD+PHjGT16NGvWrGHmzJnMnz/fXR9BRESArBw7x1JSSEzPYOvxbRxIPkxalo20rJxT77Z8jnNIz7blez6r72G8Q9fkbXBdb1JgsmRLr33OeJ0zDKdmGfKUOTUTkaecfzsWg91k0cj/CsdswqlZBUfZ4lp3albCtc2Cl9VK1xo98bZa8fSw4Gm14OnhgZfV49S5Cl6WXhqsFit1guq4NQapYLLSwJwnmTmxA2J35t+WeAD2/gJ+Vc9/rR3fFz2+4lDUhKh6M/DyK5lYzmYMZJ2Edrefu5+nL3QZAx7W0omrDHNr4rRhwwZ69erlPD59L9KwYcOYM2cO0dHRHDx40Nlev359fvjhBx5++GH+97//UatWLd566y1tRS4ikg+73ZCckU16to3MbDuZOXaycuxk5thOvZ9+uR6f2ScjO4eT2clk2mxk59hJy0kl1vY32Tl2UnNOkuL5O7bsICz+BXyxOZsV8Dv1yn0rlDr+rUjJjqVb9Wvx9LBiwVA7sD6RAfXwsjoSDT+rD2EB1fD08MDb6oGXp8VZ9rRa8LJ64GW16Mu/yMWw2yDpEOxd4Uh8jB3Wz4SgGoU/x56fSyy8YnHZY+Cf/20ghWa3QWRHqFLIe+sDqoOnllaWZRZj8tlLsQJLTk4mJCSEpKQkgoO1bEBEypdsm5341CxiT2YSezKL2JRMYk9mEpfqKJ84mUncSUd7fGoWOfa8/4m3WE/iGfQ3eGQVeB2v4M0Y44mn/4ELjjXItMLr1MyJl9Xj1CyKI3FxzKQ4jj1PzbicLTY9lmsaXsPA+gMJ8wtTsiNSHDKSHK+zpRyDg2tgw0wIyrtLsZPdBofXlVx8BWl4JfkuZM1IhLrdoFqj85+jSl2o1f78/XyrOG5Sk0qhKLlBubrHSUSkorHbDUnp2cSlZhHv8jqVGJ3MdCZJcSczSUjLdj2BRyYeno4vQdbA7Vgsp5a9eIOHN/gHbsdizcSCpyPx8D5cLHFX8QqnbmAT8MihTmBt2ke0pVZQdTpGtMdiseDnWUpLTUQqgoQDkFPIJV1ZKbBraRGWTRlY+y6ERMKxbWDPPv+QhP2FPDeOWZm63RyzTl5+0Lhf4ccGVoc6Xc/fz8uvwm42IOWLEicRkWKWkW1jf1wqJ1IyXZKhuNQsEk69x58qJ6Rlkc+kUD4MFu9YPHyz8ACC/a14h2wk1XflRcU6qMGgAtvSstO4tuG1NK7amKjgqIu6jkiFF7fHceM8QHo87F527g0Gfn8XgmsVfP9OcUuLdT3OL7acDKh9CVRrDE0HnPt8kR0g5Nz3EopUNEqcREQuUGJaFruPn3S+9pw4ye4TJzmckJ7fA+XPKcjXk2oB3lQN8KZagDcBfpmke/3FSbOHPWlrSLO5Lq3JPvU6LcQnBJvdxsnsk9zY2PW+z5SsFAY2GIi3h2Pb2SDvINpWb6ulbyJFlZ4Ia6fBLy9DSN3c+qSDBQ45p7OTpsJscnA6jqr1oH7PwvU3xpEoNekHHp6OGSKvi9w1TqQSUuIkInIeCalZ/HU0KU+SFHuy4HuEQvy8qBHsS2iAN0H+2aR7/0EKuwj09sfH0wNfLys+nh74eHrw3f6FhPqGYoB4IMaWxcn0k5Ce/7kj/CMAyLZn42Hx4NXLXuWSGpcU/wcXqciMgZitjpmYbd8UbinYhlm55YKSpeBIx3taPES0hNqdCj6f1duRzPiFQkSLwscuIm6hxElE5AxJ6dn8fSSJLUeS2Ho4iS1HEjkUX0AGA9QK8aVeuCcZgYvw8U4nyNeLIF9PfDw9sFgsfLPnG7CRmwQVcKr4jPh8632sPlxZ50rC/cO5scmN1A+pf3EfUKQyiN3lmM3JSIZtX4Nfldy2xENwYNXFX6PfS1D3jPtzvAOhetOLP6+IlFlKnESk0rLbDVuOJLFhfzxbDiex5XAi++PS8u1br5o/9cMNfiH7iQj2JtPjMLFZ+1kT/RtbATJOvZILvl6AVwC96vSibnBd1wYDob6hdIjo4FIdFRyFt/U8T3UXqcxs2XDyOPzwKFi9HHXpibDvl6KdJ6KVY4ao493n7+sTCO3ucE3GRKRSUOIkIpVKYloWv+6KZcU/x/ll5wniUvMut6sT6kebyCq0rh1CtSrxfHLgVXYm/EMcQNKpVz7qBdfLc38RQDW/avSJ6oPvxT6JXqQyyM5wbFKQfBSObIBN88A3JG+/XT+e/1y1O0N2umNHuageufX2HMdsUZUoR5uISCEocRKRCs0Yw/boFL79exs/7V/Kofh0nPs2eEOQvwf1wgKoXdWf4IAs/kpaQY2ACDKA/+3P/1klkYGR1A6sTWx6LFdFXUXdoLpcUecKQnzy+XInIoW39XP4YuSFja1SF7qPzT2ufzlUb1I8cYmIoMRJRCoQm91wIC6VncdS2BFzkp3HUth4IIET9j/wrzMXvMEnnwfb7wf2JwAJjuODKXkf+tqlZheGNh9K91rd8Tq9JEhECpYcDTln3NR3cC1s/tjx8FVPn7z9D6/P/zx1uzv6t74pb5tPENS/DLyDwKqvNCJSsvRfGREpd3JsdqKTMth9/CQ7jqWwIzqJv2J3cSg+lSybwcP7GB6+x/DwPo5X5F/4nzG2fnAjGldtUOC5M22Z1AuuR8uwlgAEewfTpWYXPD30n0uRAiVHO55dlJUGPz4Nh/OfrS20ga857jeyWMHDo1hCFBG5WPomICJlUnqWjYPxaRyISz31nsa++ET2Je0mNuMI+B7C2D2xeGThHboGgsArCM41F/SfS//DtQ2vLbXPIFIupcZBwv7c4x3fO+4JWjvNsdX22dt2x+899/m8g04VDGSdhKYDofXN+T+A1b8a1OlcuK3BRURKmRInEXELYwwJadnOxGj3iXj+iv2bYynpHEvOJDHNsWmDZ+AOsGTjFbIJizUDQuFc+8yF+oYCju29r25wNRYsXBp5KX2i+miJnQhAThYsfc6RDJ3twG9w7K+CxybsO/e5A6pDZgr4BMNNs6DepUqCRKTCUOIkIiUuO8fGK2vf48+YXSSmZRFjfgWbX+4mDYDFeupeCB+gOi7L684W6BXMyexk+tXrR4R/BDZj45KIS7gq6qoS/BQi5cDPL0JKTD4NBjZ9BL5VICOxcOeqUtc5lLQ46DTcMUvUuE/evlYvqNkOPKwXFLaISHmgxElEip3NbtgenczqPbGs3hPLhrS3sARuce1kTSe/v0MHeFahik8VvKweWE/9pTomLYY7mt+BMYZhLYdp9zoRAHPGnx52Lob5t55/zNlJ02WP5e2TkwldxmibbhGRsyhxEpGLlpyRzZKdW1mw60OiTx4jMdWQbbcD4BW0DUtgbt9uVe+kqr83UVWqc2X9bvh45t74Xd2vOoHegWefXkSSDsP+VbBlAXj5O+4V2rui4P5XPpNPpYGgmlCnC3j5QUjtkopWRKRCUuIkIkUSdzKTXcdPsiMmhXWH9rP65KtkZFnx9N+f2ykg/00avr3+W+qF1CulSEXKkewMyErNPTZ22LvckSDtXgb/fFe481z6MPR+rkRCFBGp7JQ4iUiB9semsnLXCf6JSWHX8ZPsPn6S+NQsPLyPE9DwDUcnT/A8478koV516R91DQ2qheLh4VhqF+EfwWW1L3PDJxApZbbs3HuMMpIcs0KWfLbT3vWTYxMFq7djw4WU6MKdP6KVY8ap3e2O5KpWe6gS5diAwT+02D6GiIjkpcRJRJyycuys3x/Pz/8cZ/k/x9kbm5qnj4fPCQIavOFS52v145lu/+aSiEuoGViztMIVcb/MFFg/w7FT3dr/OZKl4tbsajh5HPo8D1Hdiv/8IiJSKEqcRCohm92w7Wgy++JSORiXyoG4NA7Ep/H3kSRSs2zOfp4eFi6pF0rDWmnUCvXgr5PfszJ6sbN9UINBvHTpS3jk9xd1kYokJws2z4Pl/wG/qnB6a5PYHfn39/By7DCXkwFV60PtTnn7pMVD29vA09vxoNf6PR3beJ9JW3mLiJQZSpxEKonMHBur98Tx418x/LTtGPGpWfn2qx7kQ6+m1bmsSSh/nPyQz3bN5684IM61353N7+SJzk+UfOAi7pSeCO9f7vpA2NQT+fdtd6djuVy3ByEoojSiExGRUqTESaSC+/toEh//fpBv/jxKSkbuAy+DfT1pWiOIuqEBhFfJxtMvmlpV/Khb1Z95/7zHU5tW5jlXuF84x9OPs+DqBbSo1qI0P4ZIyTi+3fX+omN/O+o2f+yYWUqPzzum0whoOTj3OCAMwpuXfKwiIuJWSpxEKqC0rBy++zOaeesO8uehRCyeCVh9jxJSbzORwVWpEpjF1oS1HPIK4GC2IS067Zznmz9oPq3CWpVS9CIlbMdimD/k/P3OTJqaDIBr34LA8JKLS0REyjQlTiIVyD8xyXz8+0G+3LQXe+QbeATGEXTGH8LtwKFsOJTgOE7Ndt38oWFIQ6weVgAOJB/gg/4f0DKsZSlFL3IRTs8UAdhtsOlD8K92VicD277Of3zEGX8YSDwEbYdAYAQ0HeB49pF2rBMRqfSUOImUczk2O9/8eZSP1h5g09H9+ER8h1f9v8hvu4ZW1Vphx07/ev2xGRstqrWgTmAdACICIvC2epdu8CIXI/Ok44Gw34+/sPGXPQ4dhkJIHW3CICIi56XESaQc+2XnCf7z/TZ2J23HJ3wRgY335unz+TWfE+obSqhvqHM2SaRc2vkjxO+D9dMhbnf+fer1dLzbbeDtD036u7YbA9UaQsMrlSyJiEiRKHESKYd2H0/hP99vZ8We3fjV+YCA0KMu7d1qdmNI0yFcVucyvDy83BSlyEXITIENs3KPo7fAX58X3P+6/0G7O5QMiYhIiVHiJFIOZOXY+etoEhv3JzgeULtnG34N/ktgY9d+Vze4mvva3kfd4LruCVSkKOw2iN3pmAUCSD4CB9eC1QtWTC54XPNrwDsI2twMUT3A06d04hURkUpNiZNIGWSMYc+Jkyz/5wQrdh5nw/4EMnPsAFgDduLfYJZL/zC/ML667itCfELcEa5I4Rz5A356BmK2Orbwjt9TuHFtb3O8e1gdW4FHdiy5GEVERAqgxEmkjDDGsOFAAt/+eZSf/znO4YT0Uy12PIO2EVT7ozxjutXsxvt93y/dQEXOZfN8iN7sKP/9FdizweoDKa7LSclMcj0OqO54Tz3huP+oShREtITOo0s6YhERkUJR4iTiRna74Z+YFBb9Fc2Xm45wOCEdD+/jeIcvJrD6Pjw9PLBZUvMd+3z357mh8Q2lHLHIGU6egB+fAi8/x/Ge5ZB06PzjqjeHXk85tvsOqQMhkSUbp4iISDFQ4iRSitKycvgnJoUNB04wf+/rxKWmk5Vj8ArZjInwIKiG3aW/7azx1za8lqEthtKoSiM8PfQ/Xykl2emw9xeI3wt7l4PvqSWhWz8reEzPRx3v9hzHPUkeno4EK6yJNnAQEZFySd+8RErYX0eSmLVqH5sPJbIvLhXjkUpQkxccjQFwes87i8U1aWpbvS0TukzAx9OHYO9gwvzCSjdwqdyMgf2rIPkofHnPufsG1YJLRjrKdht0vBuCIko8RBERkdKkxEmkhOw6lsKbS3fyw9YYwI532M8ENluap9/4jo9itVjw9fTl0shL8bB4EOEfgUV/lRd3ycmC93rCiX/ytlVvBrU7QXgLx3HNtlDv0tKNT0RExA2UOIkUo192nmDxXzGs2xfHnhOpeHgfxz9qIVb//Xn6XlLjEt7r/R5eVj1nScqQY3/DtO6udQ2vBC9/uHWee2ISEREpA5Q4iRQDu93w6o87ePeX3O2VLRYIaPhGnr4v93yZ3lG98bHq2TNSylLjID0+9/jkMdj/G2ycDUE14OimvGMe/htCapdejCIiImWUEieRi5SWlcO4Tzbz07ZjAAzpVIdGdeN4a/tYZ5+mVZvy5hVvUie4jrvClMoo8SDE/AUbZsLuvMtEXaREux53vgcGvKqNHERERE5R4iRyEaKT0hn1wQb+PpqMt9WDV25qTZbfb7z4+4vOPt4e3nx+7edujFIqNLsdYrY4Ep9dS2D7N47nJiUfLniMb5XcckYi1OkK4c2g6SDw9oe63RwPmxUREREnJU4iFygpPZsh768mhsWE1E6mTs1Ynt2y06XP3S3vZnzH8W6KUCq0+H3wVrvC96/b3fEw2ebXgO6rExERKTIlTiIXwBjDw5+uIyF8HD6AHThw0rXPB/0/oENEB3eEJxVR5kl4owUYO2Sl5N/HL9Sx611kB2hxPXj5QkQrLbcTEREpBkqcRIooI9vGW8u3sp4xLvX3t72fbHs23Wt1p114Oz2gVorPL6/C8v/k31anK9w0C0IiSzcmERGRSkbf7EQK4XhyBp//cZjfdsey/vBefOpPdmnfctcWPXdJilfmSfjjA/jxadf6ao3h9gWOWaQq9cDDwy3hiYiIVDZKnETO44+DCYyeu55E/sTqewSf+sucbVFBUXw3+Ds3RicVRmosHN/ueOjsD4/m32fUz1C7Y+nGJSIiIoASJ5Fz+mTDPzy/5mWsdTbif1bbrU1vZULXCW6JSyqIhAPw+XA4svHc/a5+EzoO171KIiIibqTESSQfxhjeXLqL2Udvxhrs2tY3qi/XNbqOy2pf5p7gpHwzBo5vg2ndC+7TdCD4h8LA1x0bPIiIiIjbKXESOUtGto1HPvuTZXGv4nVG0vRCjxfoE9WHAK8A9wUn5dfupTD/NrBl5W2zesPIn6BW+9KPS0RERApFiZPIGYwxjPtkM4u3HSKo2d/Oem3+IEVmDKx6A1b9H2Qm5d8nsiOMXKoNHkRERMoBJU4iZ/huSzQ/7f2doGbTnHUz+85U0iSFF7MVNsyGbV9BWlze9lY3weVPQPUmpR6aiIiIXDglTiKnHE/J4N/L3yagXu4ueYFegXSu2dmNUUmZZMuGfb86kqRDv4N3INhz4O+F+fe/dDy0vQ3CGmuDBxERkXJKiZMIsHTvGp7+6WPsVVc46+5sfiePX/K4+4KSsiduD3z7L9i/8vx9AyOgx78cCZN/aMnHJiIiIiVKiZNUamuOruGeJfc4Dvxy6xdeu5DGVRu7JygpW9ITYP8q+OYhR/ls1RpBwyuhaj3HfU3hzaBR71IPU0REREqWEieplLLt2cz9ax5TNr3uUt+kSkvGdrhPSVNll5MJf8wt+EG0tS+BzvdAs6vB++wnfImIiEhFpMRJKp09iXu4/uvrXeqqZvfhgxueoX61qu4JSsqGnEyYd5Pj/qX81OsJN8+BgLBSDUtERETcT4mTVDoPLh3ncnxn/Uk83vMG7ZxXmaUnwNudIC02b9sN70HrW7RluIiISCWnxEkqlf/9/jWHU/cD4JPZhq9vmUFkFb9zD5KKK/EQLHocdvyQt23sZgitX+ohiYiISNmkxEkqjZm//cO7u//tPP70xteVNFVWOZnwYnje+tCGMGIxBObTJiIiIpWaEiep8LJtdiZ9+zdfxo3G49Rv/LtXzaBBtRruDUxKX3oivBKVt94/DK6fCo376jlLIiIiki8lTlJh2eyG33bH8tbyv/gr+128glIBqB9Snx61u7g5OikVdhsYO7zTCZIOOx5Se7Zn48HDWvqxiYiISLmixEkqpMMJaQyfvZ4D9i/xqb4ML9/cto8Hfuy+wKRkGQPRm2HpJNi7vOB+YU3g7u+1JE9EREQKTYmTVDh7Tpzkzhm/E52UQVDzZS5tn1z9CYHegW6KTEpEapxjJun3abDqzYL7+VeDMavAt4qevSQiIiJF5vb9dadOnUr9+vXx9fWlY8eOrFy58pz9582bR9u2bfH396dmzZoMHz6cuLi4UopWyrrVe2K5+d01RCdlULdm7u/F21e+zdZhW2lZraUbo5NilXgQng+D/zaA15vkTZoiO8GNM+GxPfDUYXh8LwTXUtIkIiIiF8StidOCBQsYN24cEyZMYNOmTfTs2ZMBAwZw8ODBfPuvWrWKu+66i5EjR/L333/z2WefsX79ekaNGlXKkUtZY4xhxsq9DJ25jvjULJrWSSehyn+d7Z1rdHZjdFJsEg/C7qUw/3aY0hrs2Xn73P4ZTEyE0cug9U2Oh9X6BJV6qCIiIlKxWIwxxl0X79KlCx06dGDatGnOuubNm3P99dczefLkPP1fe+01pk2bxp49e5x1b7/9Nq+++iqHDh0q1DWTk5MJCQkhKSmJ4ODgi/8Q4nY2u+H5b//mgzUHALihXU2WZg5ztj/T9RluaXqLu8KT4mC3wfOh+be1uA5ueB+XG9lERERECqEouYHbZpyysrLYuHEjffv2danv27cvq1evzndM9+7dOXz4MD/88APGGI4dO8bnn3/OoEGDCrxOZmYmycnJLi+pOOx2wyOfbuaDNQewWGDCwKYuSVOPyB5KmsozWzYc/D3/pKn2JTB6OdwyV0mTiIiIlDi3bQ4RGxuLzWYjIiLCpT4iIoKYmJh8x3Tv3p158+YxZMgQMjIyyMnJ4dprr+Xtt98u8DqTJ09m0qRJxRq7lB1v/byLrzYfxctq4Y1b2rHu5DSX9jcuf8NNkUmxeCEsb93ERD1rSUREREqd2zeHsJz1BcgYk6futG3btjF27FieffZZNm7cyOLFi9m3bx9jxowp8PxPPfUUSUlJzldhl/RJ2ff9lmimLN0FwEP9/Xl6cz++2v2Vs33LXVvw99JGAOVO0mH46gF4LsS1vs2t8FySkiYRERFxC7fNOIWFhWG1WvPMLh0/fjzPLNRpkydPpkePHjz22GMAtGnThoCAAHr27MmLL75IzZo184zx8fHBx8en+D+AuNWWw4k88sVqfMKXEVUjhel7N7u0f3L1JwUm4FIG2XLgyAZY9DhE/5m3/bmk0o9JRERE5AxuS5y8vb3p2LEjS5Ys4YYbbnDWL1myhOuuuy7fMWlpaXh6uoZstVoBx0yVVHypmTn8b/luZqzch1eD/+LhmUr0GRur9Ynqw6Tukwjy1i5qZZ4xEL8X5l4HSfnMBAfXhm73Q/uhpR+biIiIyFnc+gDc8ePHM3ToUDp16kS3bt14//33OXjwoHPp3VNPPcWRI0eYO3cuANdccw2jR49m2rRp9OvXj+joaMaNG0fnzp2pVauWOz+KlILjyRnc9O4aDsangSUbH89UZ9tD7R+iW81utK7e2o0RSqFkZzi2FF9wR/7tjfpA/5chrFHpxiUiIiJyDm5NnIYMGUJcXBzPP/880dHRtGrVih9++IGoqCgAoqOjXZ7pdPfdd5OSksI777zDI488QpUqVbjyyit55ZVX3PURpJSkZuYwfM56DsanUauKleCGMziS5mhbd8c6/Dz93BugnFt2OiQdccwsfXh93nb/anDvSscDarXEUkRERMogtz7HyR30HKfy51hyBvd9tJE/DiZSLcCbwMaTic88AUCQdxCrb8t/+3opI/b/BnMG5t/W5wXo9iB4uH2fGhEREamEipIbuHXGSeR8Nh1M4J4PN3IiJZMgHyvVmk0hOu2Es/2TQZ+4MTop0Ko3YflLjhmkhP259T4hkJkEvSbA5Y+7LTwRERGRolLiJGVWSkY2Yz5yJE1NInyIDn2Y6LTc9lW3riLEJ6TgE0jpMwZeqQcZiY7jM5Om2z+DJn3zGSQiIiJS9ilxkjLr9Z92ciw5k6hqvkSHjnNp++POP/CyerknMCnYkY25SRPAjTOhShRUawj+oW4LS0RERORiKXGSMmnTwQQ+WLMfMMSHj3PWV/WpyoohK/Cw6J6YMuPIH7B+Bmye51r/7xPg6e2emERERESKmRInKXNOZubwr082Ywy0a/UHe2y5bb8M+UUPti1Llj7nuJ/pbJ1GKGkSERGRCkWJk5Q5r/24g4PxaURW8WOP7TNn/aahm5Q0uZsxkBYHB9fmfQ5T1XrQfSy0vEHL8kRERKTCUeIkZcrOYyl8uPYAANWbTCc5xVE/qfskPD306+pWxsC8mxwPrz3bQ3847mMSERERqaD0TVTKDGMML3y3DZvdcFWLYNal/OVsu7rB1W6MTMjOgFeiICfDtb75tXDTLNBGHSIiIlLBKXGSMsEYw0drD7ByVyzeVg8Gd7Wwbo2j7bfbfsPbqvtl3CY1Fr4c45o0TYgBLz/3xSQiIiJSypQ4SZkw8Zu/mbvGsUTv7p4RPLlmmLMt2PvcT3GWEnRsG0zr5lr3TBxY9Z8OERERqVy0p7O43VebjjB3zQE8LPBo3ybMP5abNP27y7/dGFklt3RS3qRp1M9KmkRERKRS0jcgcRub3fDLzuM885XjXqahl/nw3qHBznY/Tz+GNBvirvAqp7R4eLV+3vo+L0CPsaUfj4iIiEgZocRJ3CItK4ch761l65EkADpEVWHh8TEufVbdusodoVVeWz+HL0bmrX9gHVRvWvrxiIiIiJQhWqonbvF/S3ex9UgSQT6ejOhRn/v62Z1tl0Zeypa7tmhDiNIUt8c1aarbHf71Jzwbr6RJREREBM04iRus3RvHjFX7APi/29pxZbMInlz5pLN9Wu9p7gqtctr7C8y9Nvf41o+h2SD3xSMiIiJSBilxklJjjGHWb/uZ/MN2bHbDoDY1ubJZBAArD68EoGdkT3eGWLmkJ8D/tYWMpNy6no8oaRIRERHJhxInKRXpWTYe+WwzP2yNAeCatrV4eXBrAH7a/xPJWckA9Inq47YYKxVbDrxSz7XuuqnQ/g63hCMiIiJS1ilxklIxedF2ftgag5fVwjNXt2Bo1ygsFgsAj/zyiLNf76je7gqx8ojZCvNvc617fB/4h7onHhEREZFyQImTlLgN++P5cK3j4bbT7+rEFU3DnW17k/Y6yy9d+hJB3kGlHl+lYQz8/AKsfN21/rmk/PuLiIiIiJMSJylxU1fswRi4uWNtl6QJYPLvk53laxpeU9qhVR5JR+DNFq51La6Hq551SzgiIiIi5Y0SJylRaVk5rNodC8Doyxq4tC05sIS10WsBx8NupYQc3QzvX+5aN3Ip1LnELeGIiIiIlEdKnKRErdwVS1aOnTqhfjQOD3RpG79ivLP87fXflnZoFV/mSdg4G376d25d00Fw6zw4dX+ZiIiIiBSOEicpUSt2nADgqmYRzs0gAPYl7XOWH+74MBEBEaUeW4X3WhPITs097voA9H/JffGIiIiIlGNKnKRE/XkoEYCuDaq51D/x6xPO8vCWw0szpIrvry/gi1Fg7Ll1/SZDt/vdF5OIiIhIOafESUpMRraNncdSAGhTO8RZvyFmA9vjtwPQPry9y0yUXITMFJhcO2/9s/HgYS39eEREREQqEA93ByAV1/boZHLshrBAb2qG+Drrh/+YO8P0Ss9X3BFaxbN5ft6k6dLx8MQBJU0iIiIixUAzTlJith5xPB+odWQIFouFQ8mHGPjlQGf7sBbDqBlY013hVQx2Ozxf1bWuaj0Yu1kbQIiIiIgUIyVOUiKMMXz3ZzQAbWpXIT4j3iVpAnj0kkfdEVrFcXw7TO3qWjfiR6jbNf/+IiIiInLBlDhJiViy7Rjr9sfj4+nBkEvq8NG26c625qHN+WjgR26MrgJYcCdsP2sL9wkx4KXnYYmIiIiUBCVOUuyybXZeXvwPACMvrc/vJxYzfasjcQr3D+fTaz51Z3jl218L4fOzdiGs1QHuWe6eeEREREQqCSVOUuw+WX+IvSdSCQ3whtAfeHb1bGfbxG4T3RhZOXbkD5jeK2/9IzsgqEbpxyMiIiJSyWhXPSlWKRnZTFmyE4BxvRuzJfYPZ9u03tO4rPZl7gqt/EpPzJs03TwHnktS0iQiIiJSSpQ4SbF6edE/xKVm0SAsgNs612VH/A4ARrQawaWRl7o5unIoORpeico9bnY1/PsEtLzBfTGJiIiIVEJKnKTYLNl2jHm/HwTg+etaEZdxnAxbBgBtwtq4M7Tyac1UeKNZ7rHVB26dB57e7otJREREpJLSPU5SLFIysvn3V1sBGN2zPpc2DmP8ivHO9h6RPdwVWvmTkwmvNoCsk7l1gRHwwDr3xSQiIiJSySlxkmIxY+U+jiVnElXNn0f6NiXHnsOSA0uc7b6evm6MrpyZ0to1adKzmURERETcTomTXLSUjGxm/bYPgMf7NcPXy8q0zdOc7W9e8aa7Qis/bDmw/Zu8W41POAZeSjpFRERE3E2Jk1y077dEk5KRQ4PqAQxo5djlbeqfU53tvaN6uyu08mH/bzBnYN76x/cpaRIREREpIy5oc4icnByWLl3Ke++9R0pKCgBHjx7l5MmT5xkpFdEXfxwG4OaOdfDwsPDHsdwtyEe3Hu2usMo2Ww788z3MuTpv0nTVs/B0NPiHuic2EREREcmjyDNOBw4coH///hw8eJDMzEz69OlDUFAQr776KhkZGbz77rslEaeUUWv2xLF+fwIWC9zQPpIcew7DFg9ztj/Y/kE3RldGZWfAfyLy1l/5b+g+Fjx9Sj8mERERETmnIs84/etf/6JTp04kJCTg5+fnrL/hhhtYtmxZsQYnZdumgwkMn+PY6W1g65rUCPHli51fONvva3sfHhbteO9i/295k6baneH+tXDZY0qaRERERMqoIs84rVq1it9++w1vb9dnyURFRXHkyJFiC0zKvpmr9pGRbadn4zBev7ktSZlJvPj7i872+9vd78boyhi7HeL35F2W90wcWHWroYiIiEhZV+RvbHa7HZvNlqf+8OHDBAUFFUtQUvYZY/h9XzwAD/RqhK+XlcW7lzvbp141taChldP/tYGkQ7nHvZ+DHuPAYnFXRCIiIiJSBEVeR9WnTx+mTJniPLZYLJw8eZKJEycycGA+O4NJhbTnRConUjLxtnrQrk4VAP6J/weAar7V6Fm7pxujK0NSY2FGH9ekqcMwuPRhJU0iIiIi5UiRZ5zefPNNevXqRYsWLcjIyOD2229n165dhIWFMX/+/JKIUcqg93/dA0CXBqH4ellJyUph3vZ5ALSo1sKdoZUN2RnwUi0wZ83OTkxUwiQiIiJSDhU5capVqxabN2/mk08+YePGjdjtdkaOHMkdd9zhslmEVFy7jqXw2UbHFuTjejcBoPv87s72PlF93BJXmXL2BhA12sCIxUqaRERERMqpIidOv/76K927d2f48OEMHz7cWZ+Tk8Ovv/7KZZddVqwBStnz+cbDGAO9m0fQMaoqexP3Ots6hHfghsY3uDE6Nzu+HaZ2da2bcEwPshUREREp54p8j1OvXr2Ij4/PU5+UlESvXr2KJSgpu4wxfLclGoAbO0QCcN3X1znbPxjwgVviKhMSD+VNmp6OVtIkIiIiUgEUOXEyxmDJZ7lRXFwcAQEBxRKUlF1bDidxJDEdf28rVzQN52TWSWdbh/AObozMzWw5MKVV7nHza+HZePD2d19MIiIiIlJsCr1Ub/DgwYBjF727774bH5/cB3XabDa2bNlC9+7dCxouFcSavXEAXNooDD9vK60/6OZsm953urvCcp+Tx+Gz4XBgVW5di+vg5g90P5OIiIhIBVLoxCkkJARwzDgFBQW5bATh7e1N165dGT16dPFHKGXKxgMJAHSKqsoVC65w1veq0wtvq3cBoyqg7HRYPwN++rdrfXBtuGWue2ISERERkRJT6MRp9uzZANSrV49HH31Uy/IqIWMMf5xKnPxC9hG3P87ZNqXXFDdF5Qa/vgY/v+Ba17gv9HoaarZzS0giIiIiUrKKvKvexIkTSyIOKQd2HjtJXGoW3lYPdqf+5qxfc9saPCxFvl2u/MlKg/91dn2YrU8w3PYJ1OvhvrhEREREpMQVOXEC+Pzzz/n00085ePAgWVlZLm1//PFHsQQmZc/3W44C0K2JDwt3f+6sD/QOdFdIpccYeKmma93tn0KTfu6JR0RERERKVZGnCd566y2GDx9OeHg4mzZtonPnzlSrVo29e/cyYMCAkohRygBjDN9tjQZy+IN/Oev/r9f/uS+o0rR2quvxY3uVNImIiIhUIkVOnKZOncr777/PO++8g7e3N48//jhLlixh7NixJCUllUSMUgas3RvP3hOpBDZ801nn7+nPlXWvdGNUpeToJvjx6dzj55IgoJr74hERERGRUlfkxOngwYPObcf9/PxISUkBYOjQocyfP794o5MyY+qK3QBYvHM3hFh7+1p3hVM67Db4fCS8f0Vu3S0fui0cEREREXGfIidONWrUIC7O8eU5KiqKtWsdX5737duHMaZ4o5My4VB8Git3xWL1yP33/eLaL/J9EHKFkZ4Az1eDv3Lv5aL3JGhxrftiEhERERG3KXLidOWVV/Ltt98CMHLkSB5++GH69OnDkCFDuOGGG4o9QHG/v48mA9AgMsFZFxUc5a5wSt6ORfBKPeCMPwSM2wqXjnNTQCIiIiLibkVOnN5//30mTJgAwJgxY5gzZw7Nmzdn0qRJTJs2rcgBTJ06lfr16+Pr60vHjh1ZuXLlOftnZmYyYcIEoqKi8PHxoWHDhsyaNavI15XC23XMsRzTBP8CQIBXAD5WH3eGVHLi9sD8W3OPfUJgwjGoUtd9MYmIiIiI2xV5O3IPDw88PHLzrVtuuYVbbrkFgCNHjhAZGVnocy1YsIBx48YxdepUevTowXvvvceAAQPYtm0bdevm/0X1lltu4dixY8ycOZNGjRpx/PhxcnJyivoxpAh2Hj8JGI7Zfwcgwj/CvQGVlOg/4b3Lco97/Rsuf8x98YiIiIhImWExxXBjUkxMDP/5z3+YMWMG6enphR7XpUsXOnTo4DJT1bx5c66//nomT56cp//ixYu59dZb2bt3L6GhoRcUa3JyMiEhISQlJREcHHxB56hMjDH0em0FhzI241/XMbP3bu936RFZwR74agxMqpJ73PxauGUuVOT7uEREREQquaLkBoVeqpeYmMgdd9xB9erVqVWrFm+99RZ2u51nn32WBg0asHbt2iItmcvKymLjxo307dvXpb5v376sXr063zHffPMNnTp14tVXXyUyMpImTZrw6KOPnjNZy8zMJDk52eUlhbdi5wn2x6U5kyag4iVNALE7c8tXPAVDPlTSJCIiIiJOhV6q9/TTT/Prr78ybNgwFi9ezMMPP8zixYvJyMhg0aJFXH755UW6cGxsLDabjYgI12VfERERxMTE5Dtm7969rFq1Cl9fX7788ktiY2O5//77iY+PLzBpmzx5MpMmTSpSbJLrvV/2YPGKdR4/2flJN0ZTgv7X2fFuscIVFfQzioiIiMgFK/SM0/fff8/s2bN57bXX+OabbzDG0KRJE37++eciJ01nOntLa2NMgdtc2+12LBYL8+bNo3PnzgwcOJA33niDOXPmFDjr9NRTT5GUlOR8HTp06IJjrWz2nDjJ2r3xeAcccNbd0fwON0ZUQk6cMdvUZoj74hARERGRMqvQM05Hjx6lRYsWADRo0ABfX19GjRp1wRcOCwvDarXmmV06fvx4nlmo02rWrElkZCQhISHOuubNm2OM4fDhwzRu3DjPGB8fH3x8KugOcCVs4wHH9uPeNT8DINT3wu4rK9NyMuF/l+QeXz/VfbGIiIiISJlV6Bknu92Ol5eX89hqtRIQEHDBF/b29qZjx44sWbLEpX7JkiV079493zE9evTg6NGjnDx50lm3c+dOPDw8qF279gXHIvnbcjgRi1ec8/jmJje7MZoS8mJ4brn1zbqvSURERETyVegZJ2MMd999t3P2JiMjgzFjxuRJnhYuXFjoi48fP56hQ4fSqVMnunXrxvvvv8/BgwcZM2YM4Fhmd+TIEebOnQvA7bffzgsvvMDw4cOZNGkSsbGxPPbYY4wYMQI/P79CX1cKZ92+eLyr5T5X68H2D7oxmmJmy4EXquUeW73hxhnui0dEREREyrRCJ07Dhg1zOb7zzjsv+uJDhgwhLi6O559/nujoaFq1asUPP/xAVFQUANHR0Rw8eNDZPzAwkCVLlvDQQw/RqVMnqlWrxi233MKLL7540bGIq+ikdHYeO0lQ87UAhPuFn2dEOTP9CtfjZ064JQwRERERKR+K5TlO5Yme41Q4n244xJPfLiagwVsAPNbpMe5qeZeboyom+36FD67JPX42ATwKvWpVRERERCqIouQGhZ5xksrDbjfMW3sAq99hZ91tzW9zY0TFaNET8Pu7uccPrFfSJCIiIiLnpW+MksenGw7x5+EkfP3iAehVpxdeHl7nGVUO7F3hmjRd8TRUb+K2cERERESk/NCMk+Tx0e+O5zbVq3mS/elgMzY3R3SRjIH5t8LOxbl1D/8NIdqJUUREREQKR4mTuMjItvFPdAoA+9M3AFAnqI47Q7o4OVnwYnXXur7/UdIkIiIiIkWixElcbItOJsduqBp6mJxTdVc3uNqtMV2U969wPX7oD6jW0C2hiIiIiEj5dUH3OH344Yf06NGDWrVqceCAY1nXlClT+Prrr4s1OCl9Ww4lAlA9fJ+zrlVYKzdFc5H+/gqO/517/HS0kiYRERERuSBFTpymTZvG+PHjGThwIImJidhsjvtfqlSpwpQpU4o7PillWw4ngSWbaMv3ALSt3tbNEV2ETR/llsdvB29/98UiIiIiIuVakROnt99+m+nTpzNhwgSsVquzvlOnTmzdurVYg5PS9+fhRDyDcv8dW1Zr6cZoLpDdDnOuht1LHMfdx0JwLffGJCIiIiLlWpHvcdq3bx/t27fPU+/j40NqamqxBCXukZSWzd7YVHxq5S5vG9dxnPsCuhDZ6fCfGq51zcrxPVoiIiIiUiYUecapfv36bN68OU/9okWLaNGiRXHEJG6yYudxjLHhFexInK5ucDV+nn5ujqqIPrjW9fjhv6FuF/fEIiIiIiIVRpFnnB577DEeeOABMjIyMMawbt065s+fz+TJk5kxY0ZJxCil5Ke/j+ETvsh5PLjxYDdGcwGSj8LhdbnHj+8D/1D3xSMiIiIiFUaRE6fhw4eTk5PD448/TlpaGrfffjuRkZH83//9H7feemtJxCilZN3+eLxrr3IeX1LjEjdGUwS2bPjlFfj1v7l1TxwAvypuC0lEREREKpYLeo7T6NGjGT16NLGxsdjtdsLDw4s7Lill2TY7sSczCTx1/GinR90aT5G8EOZ63PleJU0iIiIiUqyKfI/TpEmT2LNnDwBhYWFKmiqIEymZYE1wHg+sP9CN0RRS/F54LsS17t5fYeCr7olHRERERCqsIidOX3zxBU2aNKFr16688847nDhxoiTiklJ2LDkDn/AfncfV/au7MZpCyMmEt87a3XFCDNQsx8+dEhEREZEyq8iJ05YtW9iyZQtXXnklb7zxBpGRkQwcOJCPP/6YtLS0kohRSsGx5AxMTuD5O5YVL54x0xnRCv59HLzK2Q6AIiIiIlJuFDlxAmjZsiUvvfQSe/fuZfny5dSvX59x48ZRo0aN8w+WMmnXsZNYA3YDcF/b+9wczXnE7XE9Hr0cPH3cE4uIiIiIVAoXlDidKSAgAD8/P7y9vcnOzi6OmMQNvtt6EKtvDAA59hw3R3MOqXHwdofc46ejwdPbffGIiIiISKVwQYnTvn37+M9//kOLFi3o1KkTf/zxB8899xwxMTHFHZ+Ugt3HUzjoNdV53K9ePzdGcw5fPwD/bZB73H0sePu7Lx4RERERqTSKvB15t27dWLduHa1bt2b48OHO5zhJ+bXxQAIWr9wd9ZqGNnVjNAX44THY9FHucYMroO8LbgtHRERERCqXIidOvXr1YsaMGbRs2bIk4hE32H38JFYfx+6Iz3Z71s3R5CM7Hda9n3t8/1oIb+6+eERERESk0ily4vTSSy+VRBziRtuPRzsXbbaq1sq9weTn7U655aFfKmkSERERkVJXqMRp/PjxvPDCCwQEBDB+/Phz9n3jjTeKJTApHXa7nT89xjmPm4U2c18w+dn+HSQfzj2uf4W7IhERERGRSqxQidOmTZucO+Zt2rSpRAOS0vXa6o+d5ctrX4nFYnFjNGc5ugkW3JF7/Ogu8LjojSBFRERERIrMYowx7g6iNCUnJxMSEkJSUhLBwcHuDsftWn/Q2lnecteWspM4zRoAB1fnHt80G1oNdl88IiIiIlLhFCU3KPKf70eMGEFKSkqe+tTUVEaMGFHU04kb/XnkqLM8rNn9ZSdpOnncNWm68hklTSIiIiLiVkVOnD744APS09Pz1KenpzN37txiCUpKx6eb/naW/3XJKDdGcoasNHitce7xE/vhskfdFo6IiIiICBRhV73k5GSMMRhjSElJwdfX19lms9n44YcfCA8PL5EgpfgZY1h6cDEEgJ81EC8PL3eH5PBSzdxyVA/wq+q+WERERERETil04lSlShUsFgsWi4UmTZrkabdYLEyaNKlYg5OS809MCql+y7EAQd4B7g7H4cSO3LKHJwz/wX2xiIiIiIicodCJ0/LlyzHGcOWVV/LFF18QGhrqbPP29iYqKopatWqVSJBS/Kb8vAWLh2OnxHvb3uPmaIDUWPhf59zjf59wXywiIiIiImcpdOJ0+eWXA7Bv3z7q1q1bdjYSkCJbvSeWZftX4VfbcXxDoxvcG1BOFrzeNPf4ktHadlxEREREypRCJU5btmyhVatWeHh4kJSUxNatWwvs26ZNm2ILTkrGK4v+wa/2POexl9XN9zd9fT/YcxzlqB4w6DX3xiMiIiIicpZCJU7t2rUjJiaG8PBw2rVrh8ViIb/HP1ksFmw2W7EHKcUnNTOHLUeSCGzmOG4d1vrcA0rapnmw9bPc47u+dl8sIiIiIiIFKFTitG/fPqpXr+4sS/n1T0wKeJx0Hr9++evuC+a9yyF6c+7xuK3g7tkvEREREZF8FCpxioqKyrcs5c/26GT86sxxHtcIqOGeQOx216RpyEdQpa57YhEREREROY8LegDu999/7zx+/PHHqVKlCt27d+fAgQPFGpwUv7+PJmH1O+w8dtsmH681yi0/HQ3Nr3FPHCIiIiIihVDkxOmll17Cz88PgDVr1vDOO+/w6quvEhYWxsMPP1zsAUrxWnf0T2f544EfuyeIf76HtLjcY29/98QhIiIiIlJIhd6O/LRDhw7RqJFjtuCrr77ipptu4p577qFHjx5cccUVxR2fFKO0rBwOJh/BN8hx3Lq6mzaG2P5dbvmZuIL7iYiIiIiUEUWecQoMDCQuzvFl96effqJ3794A+Pr6kp6eXrzRSbHacjgJ30jHNuStqrVyTxAZyfDnqZmudneCtci5u4iIiIhIqSvyt9Y+ffowatQo2rdvz86dOxk0aBAAf//9N/Xq1Svu+KQYfbrTzc9uMgZerpN73Pqm0o9BREREROQCFHnG6X//+x/dunXjxIkTfPHFF1SrVg2AjRs3cttttxV7gFJ8lhyb7ix/0P+D0g9g+7euxw17lX4MIiIiIiIXoMgzTlWqVOGdd97JUz9p0qRiCUhKRlp2mrPcr9qz7tlN79OhueVnYkv/+iIiIiIiF+iCbjBJTExk5syZbN++HYvFQvPmzRk5ciQhISHFHZ8Uk/uX3e8stwu7pPQDSDqSW+43WQ+6FREREZFypchL9TZs2EDDhg158803iY+PJzY2ljfffJOGDRvyxx9/lESMcpHsxs7GYxudxzWC/Urx4jb45VV4s0VuXbf7C+4vIiIiIlIGFXnG6eGHH+baa69l+vTpeHo6hufk5DBq1CjGjRvHr7/+WuxBysXZk7jHWU7dO5aIq3xL7+LfPASbczel0INuRURERKQ8KnLitGHDBpekCcDT05PHH3+cTp06FWtwUjzGLBnjLPuaOtQLK6UHzv79lWvSdP270GZI6VxbRERERKQYFXmpXnBwMAcPHsxTf+jQIYKCgoolKCk+exP3cjz9OAA5qfUZc3lDgnxL4f6izJPw2bDc4/t/h3a3gUeRf+VERERERNyuyN9ihwwZwsiRI1mwYAGHDh3i8OHDfPLJJ4waNUrbkZdBH23/yFk20aMZ1bN+yV80NQ4mR+Ye938FwpuV/HVFREREREpIkZfqvfbaa1gsFu666y5ycnIA8PLy4r777uPll18u9gDl4vyw7wcAbOl1aF+nOv7eF7SRYtHsWZZbDq4NXccU3FdEREREpBwo8rdob29v/u///o/JkyezZ88ejDE0atQIf/9Sum9GiiQ1OxWA7KQOXNK+aulcdNETjnerN4zbUjrXFBEREREpQYVeqpeWlsYDDzxAZGQk4eHhjBo1ipo1a9KmTRslTWWYp+XUzocnm3BJ/dCSv+Dc6yA93lFudSN4WEv+miIiIiIiJazQidPEiROZM2cOgwYN4tZbb2XJkiXcd999JRmbXKRsWzY5xrGc0mL3pX3dEpxxMgZ+nAB7V+TWDXil5K4nIiIiIlKKCr1Ub+HChcycOZNbb70VgDvvvJMePXpgs9mwWjWrUBbduehOZ7lhWFUCfUrw/qaPBsOen3OPH90NviEldz0RERERkVJU6BmnQ4cO0bNnT+dx586d8fT05OjRoyUSmFyctOw0tsVtA8AYC20iw0vuYqvfcU2a7v0VAquX3PVEREREREpZoRMnm82Gt7e3S52np6dzZz0pW5YdzN3ZLnXX07SODC6ZCxkDP03IPX5kB9RsWzLXEhERERFxk0Kv3TLGcPfdd+Pj4+Osy8jIYMyYMQQEBDjrFi5cWLwRygV5etXTzrKxBdExqoQ2hji0Lrd8+2cQVKNkriMiIiIi4kaFTpyGDRuWp+7OO+/Mp6e427HUY85ydnJLIoJ9aFVSM04n/sktN+pdMtcQEREREXGzQidOs2fPLsk4pBjtTNjpLGccuZ3BXSKwWCwlc7Hf33O8h9QFj0Kv/BQRERERKVf0TbcCikmLAcCSWQ+w0qdFRMlc6PAGOP63o9zoypK5hoiIiIhIGeD2xGnq1KnUr18fX19fOnbsyMqVKws17rfffsPT05N27dqVbIDl0Px/5gOQYzIIDfDm0kZhxX+RlGMw46rc48seL/5riIiIiIiUEW5NnBYsWMC4ceOYMGECmzZtomfPngwYMICDBw+ec1xSUhJ33XUXV1111Tn7VVbx6fEAGFsgg1rXxMtazP/MMX/B601yj6N6QEhk8V5DRERERKQMcWvi9MYbbzBy5EhGjRpF8+bNmTJlCnXq1GHatGnnHHfvvfdy++23061bt1KKtHyp6lsNgJzk1lzfvlbxntwYeLdH7nFoQ7jj8+K9hoiIiIhIGeO2xCkrK4uNGzfSt29fl/q+ffuyevXqAsfNnj2bPXv2MHHixEJdJzMzk+TkZJdXRbc70bE5RJhPFB3qVi2+ExsDL9fNPW59C4z9A7z9i+8aIiIiIiJl0AUlTh9++CE9evSgVq1aHDhwAIApU6bw9ddfF/ocsbGx2Gw2IiJcNy6IiIggJiYm3zG7du3iySefZN68eXh6Fm5DwMmTJxMSEuJ81alTp9Axlkd/xf7lLLepEVW8u+m93REyz0g8B79ffOcWERERESnDipw4TZs2jfHjxzNw4EASExOx2WwAVKlShSlTphQ5gLO/2Btj8v2yb7PZuP3225k0aRJNmjTJ016Qp556iqSkJOfr0KFDRY6xPDm9MQRA/SrFeN/R949A/J7c42cToKS2OBcRERERKWOKnDi9/fbbTJ8+nQkTJmC1Wp31nTp1YuvWrYU+T1hYGFarNc/s0vHjx/PMQgGkpKSwYcMGHnzwQTw9PfH09OT555/nzz//xNPTk59//jnf6/j4+BAcHOzyqsgsOJKZ7KS2RFYtxiV062fklp+J1TObRERERKRSKfK333379tG+ffs89T4+PqSmphb6PN7e3nTs2JElS5a41C9ZsoTu3bvn6R8cHMzWrVvZvHmz8zVmzBiaNm3K5s2b6dKlS1E/SoW0K3EXALb0OtSu4lc8J/39jCV5t38KVq/iOa+IiIiISDlRuBuFzlC/fn02b95MVFSUS/2iRYto0aJFkc41fvx4hg4dSqdOnejWrRvvv/8+Bw8eZMyYMYBjmd2RI0eYO3cuHh4etGrVymV8eHg4vr6+eeorK2MM2+K2nTqyUrdaMcw4HdkIix7LPW7U++LPKSIiIiJSzhQ5cXrsscd44IEHyMjIwBjDunXrmD9/PpMnT2bGjBnnP8EZhgwZQlxcHM8//zzR0dG0atWKH374wZmURUdHn/eZTpJr2OJhznKQaUaDsICLP+m66bnl+38HD2vBfUVEREREKiiLMcYUddD06dN58cUXnRstREZG8txzzzFy5MhiD7C4JScnExISQlJSUoW638lu7LSd29Z53NNzDlPv6HiRJ7XD86e2M4/sBKOXXdz5RERERETKkKLkBkWecQIYPXo0o0ePJjY2FrvdTnh4+AUFKsUnIyfDWU7dM55OfUMv/qRLnsktd3vg4s8nIiIiIlJOXVDidFpYWFhxxSEXaenBpc6yPas6rWuHXNwJ7TZY807ucavBF3c+EREREZFy7II2hzjXQ1X37t17UQHJhZmwaoKz7GX1oEXNi1yGuHNxbnnspos7l4iIiIhIOVfkxGncuHEux9nZ2WzatInFixfz2GOP5T9ISlRadpqznBXfncHtaxPgc1GTibD6jNmm0AYXdy4RERERkXKuyN+u//Wvf+Vb/7///Y8NGzZcdEBSdImZic5y1vFB3HvnRSY6xsDB1Y5y5EVuMCEiIiIiUgEU+QG4BRkwYABffPFFcZ1OimB/8n4AjN2TuqFBNKgeeHEn3Ls8t9xv8sWdS0RERESkAii2xOnzzz8nNLQYdnKTIvt4+8enShbqF8ezm375b265bpeLP5+IiIiISDlX5KV67du3d9kcwhhDTEwMJ06cYOrUqcUanBTOL4d/AcCeWYP6kReZOJ25TC+qx0VGJiIiIiJSMRQ5cbr++utdjj08PKhevTpXXHEFzZo1K664pJDWx6x3lrPiu9Og7UUmTsuezy1fPeXiziUiIiIiUkEUKXHKycmhXr169OvXjxo1apRUTFIEX+760ln2zujAVc0jLu6EZ97fVL3JxZ1LRERERKSCKNI9Tp6entx3331kZmaWVDxSRN5WbwCyk9rwWL/m1Krid+EnO7EDjp56ZlPPR4ohOhERERGRiqHIm0N06dKFTZv0QNSyIiPHkcTaMiLp2/IiZwH/1zm33LjvxZ1LRERERKQCKfI9Tvfffz+PPPIIhw8fpmPHjgQEuN5T06ZNm2ILTs7v+33fAeBr9aZWiO+Fn8iY3HLtzlC360VGJiIiIiJScRQ6cRoxYgRTpkxhyJAhAIwdO9bZZrFYMMZgsViw2WzFH6WcV3hQkMtuh0U2qUpu+U49j0tERERE5EyFTpw++OADXn75Zfbt21eS8UgRWfHBRiYtQi9ipm/3styyX1XwDb74wEREREREKpBCJ07m1FKuqKioEgtGiiYhIwEbjnucmofXvPATff1AbvmJ/RcXlIiIiIhIBVSkzSEuaimYFLuFuxY6y20jLzBxSomBlGhHuUn/YohKRERERKTiKdLmEE2aNDlv8hQfH39RAUnhrYveAIA9qxotalS9sJP8811u+eY5Fx+UiIiIiEgFVKTEadKkSYSEhJRULFJEq6NXAeCV1YSqAd4XdpLvTz2vKTACvC7iGVAiIiIiIhVYkRKnW2+9lfDw8JKKRYpgR/wOZ7m2X6sLO8ma/+WWu953kRGJiIiIiFRchb7HSfc3lS3Tt053lruGX3lhJ1n2Qm65+9iC+4mIiIiIVHKFTpzMmQ9IFbdKyUrhx/0/AmBsvjStcQHLJ0+egJx0R3nEj+BhLcYIRUREREQqlkIv1bPb7SUZhxTBXYvucpbTj95K075BRT/Jytdyy5GdiiEqEREREZGKq0jbkUvZsDtxt7NsO9mMGiG+RT/JwbW5ZWuRbnUTEREREal0lDiVMza7zVlO3Xc/AKH+F7CjXvRmx3unkcUQlYiIiIhIxabEqZw5fPKws2zPrEFVfy88rUX8Z0yNyy23uaWYIhMRERERqbiUOJUzexL3AOBrDQDjTbVAn6KfZOnE3HLdrsUUmYiIiIhIxaXEqZz5J/4fALLtWQBUu5AH32775lRBW8yLiIiIiBSGEqdy5svdXwIQ4BEBQJOIIu6oZ8uGzCRH+d5fijM0EREREZEKS4lTOePt4ZhhsmTWAaBdnSqFH2y3wfReuccRrYoxMhERERGRikuJUznj5eEFQNyxlgC0LUritOJliNnqKIfU0UNvRUREREQKSYlTOZOSlQJAVo6FIF9PGoQFFH7wr6/mlu/9tZgjExERERGpuJQ4lSPGGI6nH3ced6lfDQ+PImzwYD21kcRNs8A/tJijExERERGpuJQ4lSNHU486y7aMmgxoVaPwg+12sDl24qP+5cUcmYiIiIhIxabEqRzZFrfNWfYkgN7NIwo/OCU36cKniDvxiYiIiIhUckqcypG49DgA7Dn+dGtYjRB/r8IPPnkst+x5AQ/NFRERERGpxJQ4lSMeFsc/l8muStcG1Yo2ePqVjnf/Io4TERERERElTuXJroRdANizqtG85gUut6vRuhgjEhERERGpHJQ4lSM7TiVOFs80mtcMLvzAf37ILV/zf8UclYiIiIhIxafEqRzZdHwjAF45kdQI9i38wA0zc8tV6xVvUCIiIiIilYASp3Kovl9XLJYiPL/p2N+O91Y3lUxAIiIiIiIVnBKnciIpM8lZbhneoGiDvfwc7zVaFWNEIiIiIiKVhxKncuJg8kFnuV2t2oUfmJkC8Xsd5QglTiIiIiIiF0KJUzmx5MASAOzZVWgZGVL4gbG7cstRPYo5KhERERGRykGJUznx6+HfHAUDjcIDCz/wwKlxQTXB27/4AxMRERERqQSUOJUTB5Idy+08shrg42kt/MD1p3bUs2WVQFQiIiIiIpWDEqdyIsfkAOBna1q0gQn7HO8NryrmiEREREREKg8lTuWE1eIJQA3fRoUfZExuuc0txRyRiIiIiEjlocSpHEjNTsV2asapeVidwg9c/XZuuU7nYo5KRERERKTyUOJUDvx3/X+d5WYRYYUfuOSZ3LJvEXbiExERERERF0qcyoHNxzc7yy1qhhZuUGpcbnnw9OINSERERESkklHiVA7sSdoDQGZsL5rVCC7coB+fyi03u7oEohIRERERqTyUOJVxOfYcZ7m6VxNC/L0KN3DLAse7d5Ce3yQiIiIicpGUOJVxR08edZYvqdGxcIN2LcktX/qvYo5IRERERKTyUeJUxi3ctdBZ7lIvsnCD5t2UW+72YDFHJCIiIiJS+ShxKuM2Hf8TAGMsXNqokDvq+Z3aQOLyJ8DLr4QiExERERGpPJQ4lXHpGb4ABGReTp3QQtyrZLdDeryj3FoPvRURERERKQ5KnMq4I4knAehUs1nhBsTtyi0H1yyBiEREREREKh8lTmVcUlYsAK0iC/n8pixHooWnL3gHlFBUIiIiIiKVi9sTp6lTp1K/fn18fX3p2LEjK1euLLDvwoUL6dOnD9WrVyc4OJhu3brx448/lmK0pSs1MweL72EAQgN8Cjdo5RuO9+BaJRSViIiIiEjl49bEacGCBYwbN44JEyawadMmevbsyYABAzh48GC+/X/99Vf69OnDDz/8wMaNG+nVqxfXXHMNmzZtKuXIS8ehhERnuXPN9oUbtHuZ493Ds/gDEhERERGppCzGGOOui3fp0oUOHTowbdo0Z13z5s25/vrrmTx5cqHO0bJlS4YMGcKzzz5bqP7JycmEhISQlJREcHDwBcVdWj7avJxX/hwLwNZhW88/IDsD/hPhKA/5CJpfU4LRiYiIiIiUb0XJDdw245SVlcXGjRvp27evS33fvn1ZvXp1oc5ht9tJSUkhNLTg+38yMzNJTk52eZUXx0+mFG3AR4Nzy436FG8wIiIiIiKVmNsSp9jYWGw2GxERES71ERERxMTEFOocr7/+OqmpqdxyS8Hbbk+ePJmQkBDnq06dOhcVd2mKT80AIJD65++ckQQHfnOUA6qDl28JRiYiIiIiUrm4fXMIi8XicmyMyVOXn/nz5/Pcc8+xYMECwsPDC+z31FNPkZSU5HwdOnToomMuLbGnEidvayHuV1pyxlLFB9aVUEQiIiIiIpWT23YQCAsLw2q15pldOn78eJ5ZqLMtWLCAkSNH8tlnn9G7d+9z9vXx8cHHp5A70pUxu48ngx8E+nifv3PKMcd7cG3wL+TW5SIiIiIiUihum3Hy9vamY8eOLFmyxKV+yZIldO/evcBx8+fP5+677+bjjz9m0KBBJR2m22Tm2DiUdAKAKn6FSPx2LnK8X/5YCUYlIiIiIlI5uXXP6vHjxzN06FA6depEt27deP/99zl48CBjxowBHMvsjhw5wty5cwFH0nTXXXfxf//3f3Tt2tU5W+Xn50dISIjbPkdJiEnKwFiTAMgyaYUfGKTnN4mIiIiIFDe3Jk5DhgwhLi6O559/nujoaFq1asUPP/xAVFQUANHR0S7PdHrvvffIycnhgQce4IEHHnDWDxs2jDlz5pR2+CXqWHImGCsAVXyqnLtzekJuObQQG0mIiIiIiEiRuP0pqffffz/3339/vm1nJ0MrVqwo+YDKiEPxaVj99wFQP+Q8ydAr9XLLVZU4iYiIiIgUN7fvqif52x6djIfPcQDSss+xVO/M2abanaEwO/CJiIiIiEiRKHEqo/6OOYGHl+Mep/bh7QvumLA/tzxqSYHdRERERETkwilxKoOMMWyP3eU87luvb8GdD28ohYhERERERCo3JU5lUHRSBqkeuwGo6lOVIO+ggjuvmOx4rxJVCpGJiIiIiFROSpzKoL+OJIGxABDoHXjuzmlxjvdOw0s4KhERERGRykuJUxn019FkLB45AHQI71Bwx+SjueX2Q0s4KhERERGRyktbsJVB244m4eF3AAAvq1f+neL3wltnbBrhX60UIhMREamYbDYb2dnZ7g5DREqAt7c3Hh4XP1+kxKkM+utIMpaqji3IkzKT8u90ZtLU+mawWEohMhERkYrFGENMTAyJiYnuDkVESoiHhwf169fH29v7os6jxKmMSUjNIiY5laBIx4xT5xqd8+m0P7dctR7cOKNUYhMREaloTidN4eHh+Pv7Y9EfIkUqFLvdztGjR4mOjqZu3boX9b9xJU5lzOGEdCzW3Afe9o7qnbfTwntzyw+sK4WoREREKh6bzeZMmqpV05J3kYqqevXqHD16lJycHLy8CrgNphC0OUQZczQpHa+qa53HYX5heTsdOtXecTh4+pRSZCIiIhXL6Xua/P393RyJiJSk00v0bDbbRZ1HiVMZE5OUgWfAroI7pMXnljvcVfIBiYiIVHBanidSsRXX/8aVOJUxR5PSweLIhgc3Hpy3w/6VueVa7fO2i4iIiIhIsVPiVMZEJ2Zg9TsCQO+6+dzftP6MjSD0FzIRERFxg3r16jFlyhR3h1HuZGVl0ahRI3777Td3h1JhHD9+nOrVq3PkyJESv5YSpzImOikdY/MFoLp/dddGux32/eoot729lCMTERGRsuLuu+/GYrFgsVjw9PSkbt263HfffSQkJLg7tBL13HPPOT/3ma+lS5e6NaZ27doVqu/7779PVFQUPXr0yNN2zz33YLVa+eSTT/K03X333Vx//fV56jdv3ozFYmH//v3OOmMM77//Pl26dCEwMJAqVarQqVMnpkyZQlpaWp5zFJeEhASGDh1KSEgIISEhDB069Lzb/B87doy7776bWrVq4e/vT//+/dm1K/eWlfj4eB566CGaNm2Kv78/devWZezYsSQl5T6uJzw8nKFDhzJx4sSS+mhOSpzKmKOJGWDJASDYO9i1MX5PbvmyR0sxKhERESlr+vfvT3R0NPv372fGjBl8++233H///e4Oq8S1bNmS6Ohol9dll112QefKysoq5ujO7e2332bUqFF56tPS0liwYAGPPfYYM2fOvKhrDB06lHHjxnHdddexfPlyNm/ezDPPPMPXX3/NTz/9dFHnPpfbb7+dzZs3s3jxYhYvXszmzZsZOnRogf2NMVx//fXs3buXr7/+mk2bNhEVFUXv3r1JTU0F4OjRoxw9epTXXnuNrVu3MmfOHBYvXszIkSNdzjV8+HDmzZtX8n84MJVMUlKSAUxSUpK7Q8nDZrObhk99Z1rNaWVazWllTqSdcO2w+GljJgY7XiIiInJR0tPTzbZt20x6erqzzm63m9TMbLe87HZ7oWMfNmyYue6661zqxo8fb0JDQ53HOTk5ZsSIEaZevXrG19fXNGnSxEyZMiXf8/z3v/81NWrUMKGhoeb+++83WVlZzj7Hjh0zV199tfH19TX16tUzH330kYmKijJvvvmms8+BAwfMtddeawICAkxQUJC5+eabTUxMjLN94sSJpm3btmbmzJmmTp06JiAgwIwZM8bk5OSYV155xURERJjq1aubF1988Zyf+/R5CrJlyxbTq1cv4+vra0JDQ83o0aNNSkpKns/70ksvmZo1a5qoqChjjDGHDx82t9xyi6lSpYoJDQ011157rdm3b59z3PLly80ll1xi/P39TUhIiOnevbvZv3+/mT17tgFcXrNnz843to0bNxoPD498v4POmTPHdO3a1SQmJho/Pz+Xa58Z99k2bdpkAGf/BQsWGMB89dVXefra7XaTmJhY4M/uYmzbts0AZu3atc66NWvWGMD8888/+Y7ZsWOHAcxff/3lrMvJyTGhoaFm+vTpBV7r008/Nd7e3iY7O9ulvl69embmzJn5jsnvf+unFSU30HOcypD4tCyM307ncYBXgGuHjXMc79Wbl15QIiIilUh6to0Wz/7olmtve74f/t4X9tVs7969LF682OUZNXa7ndq1a/Ppp58SFhbG6tWrueeee6hZsya33HKLs9/y5cupWbMmy5cvZ/fu3QwZMoR27doxevRowLFM7NChQ/z88894e3szduxYjh8/7hxvTs0cBAQE8Msvv5CTk8P999/PkCFDWLFihbPfnj17WLRoEYsXL2bPnj3cdNNN7Nu3jyZNmvDLL7+wevVqRowYwVVXXUXXrl2L/DNIS0ujf//+dO3alfXr13P8+HFGjRrFgw8+yJw5c5z9li1bRnBwMEuWLMEYQ1paGr169aJnz578+uuveHp68uKLL9K/f3+2bNmCh4cH119/PaNHj2b+/PlkZWWxbt06LBYLQ4YM4a+//mLx4sXO5YIhISH5xvfrr7/SpEkTgoOD87TNnDmTO++8k5CQEAYOHMjs2bOZNGlSkX8G8+bNo2nTplx33XV52iwWS4GxAQQGBp7z3D179mTRokX5tq1Zs4aQkBC6dOnirOvatSshISGsXr2apk2b5hmTmZkJgK+vr7POarXi7e3NqlWr8p2ZA0hKSiI4OBhPT9f/rXTu3JmVK1cyYsSIc36Oi6HEqQxJSM3C6nvIeezn6ZfbmJMJWScd5Xa6v0lERKSy++677wgMDMRms5GRkQHAG2+84Wz38vJy+fJdv359Vq9ezaeffuqSOFWtWpV33nkHq9VKs2bNGDRoEMuWLWP06NHs3LmTRYsWsXbtWueX4pkzZ9K8ee4fcZcuXcqWLVvYt28fderUAeDDDz+kZcuWrF+/nksuuQRwJHKzZs0iKCiIFi1a0KtXL3bs2MEPP/yAh4cHTZs25ZVXXmHFihXnTJy2bt3q8iW/RYsWrFu3jnnz5pGens7cuXMJCHD88fmdd97hmmuu4ZVXXiEiIgKAgIAAZsyY4Xy2z6xZs/Dw8GDGjBnObatnz55NlSpVWLFiBZ06dSIpKYmrr76ahg0bArh8/sDAQDw9PalRo8Y5/732799PrVq18tTv2rWLtWvXsnDhQgDuvPNOxo4dy8SJE/HwKNpdNbt27co3SSmMzZs3n7Pdz8+vwLaYmBjCw8Pz1IeHhxMTE5PvmGbNmhEVFcVTTz3Fe++9R0BAAG+88QYxMTFER0fnOyYuLo4XXniBe++9N09bZGQkmzZtOudnuFhKnMqQhLRsPHwdvyiNqjRybfxyTG5Zz28SEREpEX5eVrY9389t1y6KXr16MW3aNNLS0pgxYwY7d+7koYcecunz7rvvMmPGDA4cOEB6ejpZWVl5NjJo2bIlVmvutWvWrMnWrVsB2L59O56ennTq1MnZ3qxZM6pUqeI83r59O3Xq1HEmTeBIZqpUqcL27dudiVO9evUICgpy9omIiMBqtbokBxERES6zWflp2rQp33zzjfPYx8fHGUfbtm2dSRNAjx49sNvt7Nixw5k4tW7d2pk0AWzcuJHdu3e7xAaQkZHBnj176Nu3L3fffTf9+vWjT58+9O7dm1tuuYWaNWueM86zpaenu8yunDZz5kz69etHWFgYAAMHDmTkyJEsXbqUvn37FukaxpgLfmZRo0aNzt/pHPK77rni8fLy4osvvmDkyJGEhoZitVrp3bs3AwYMyLd/cnIygwYNokWLFvluBOHn51eim1+AEqcyJT41C06tnqwfUt+1MTPZ8R5SF/yqlG5gIiIilYTFYrng5XKlLSAgwPll96233qJXr15MmjSJF154AYBPP/2Uhx9+mNdff51u3boRFBTEf//7X37//XeX85y5vA8cPwO73Q44vvieritIQV+Oz67P7zrnunZBvL298/2Sf64v6WfWn5lYgWMmrGPHjsybNy/PuOrVHTscz549m7Fjx7J48WIWLFjAv//9b5YsWVKkJYVhYWHOhPQ0m83G3LlziYmJcVl6ZrPZmDlzpjNxCg4O5sCBA3nOeXrXutNL8Jo0acL27dsLHdOZLmapXo0aNTh27Fie+hMnTjgT1vx07NiRzZs3k5SURFZWFtWrV6dLly4uiTpASkoK/fv3JzAwkC+//DLP7w04duA7/e9VUsrHfxkqiYPxqYDjPxbtqrdzbTyy0fHep+jrXUVERKTimzhxIgMGDOC+++6jVq1arFy5ku7du7vstLdnz55znCGv5s2bk5OTw4YNG+jcuTMAO3bscNlmukWLFhw8eJBDhw45Z522bdtGUlKSy5K2ktaiRQs++OADUlNTncnRb7/9hoeHB02aNClwXIcOHViwYAHh4eH53n90Wvv27Wnfvj1PPfUU3bp14+OPP6Zr1654e3tjs9nOG1/79u2ZNm2aS4L3ww8/kJKSwqZNm1xm/f755x/uuOMO4uLiqFatGs2aNWP+/PlkZGS4zFqtX7+e6tWrU7VqVcCxs92tt97K119/nec+J2MMycnJBd7ndDFL9bp160ZSUhLr1q1z/p78/vvvJCUl0b1793OeF3ITv127drFhwwZn8g+OmaZ+/frh4+PDN998k++sHcBff/3FFVdccd5rXQxtR16GHIhLA4sjcfK2ers2mlN/fdFDb0VERCQfV1xxBS1btuSll14CHEuvNmzYwI8//sjOnTt55plnWL9+fZHO2bRpU/r378/o0aP5/fff2bhxI6NGjXL5Et27d2/atGnDHXfcwR9//MG6deu46667uPzyy/PMHJSkO+64A19fX4YNG8Zff/3F8uXLeeihhxg6dOg5Zz3uuOMOwsLCuO6661i5ciX79u3jl19+4V//+heHDx9m3759PPXUU6xZs4YDBw7w008/sXPnTmdSWK9ePfbt28fmzZuJjY11bnpwtl69epGamsrff//trJs5cyaDBg2ibdu2tGrVyvm68cYbqV69Oh999JEzRk9PT4YOHcqGDRvYs2cPH330EZMnT+axxx5znu+WW25hyJAh3HbbbUyePJkNGzZw4MABvvvuO3r37s3y5csL/Dk0atTonK/IyMgCxzZv3tz5e7J27VrWrl3L6NGjufrqq13uuWrWrBlffvml8/izzz5jxYoVzi3J+/Tpw/XXX++caUtJSaFv376kpqYyc+ZMkpOTiYmJISYmxiVZTUtLY+PGjUVe2lhUSpzKELsxYHH8Enh6nDUZmHHqQV/VGpdyVCIiIlJejB8/nunTp3Po0CHGjBnD4MGDGTJkCF26dCEuLu6CnvM0e/Zs6tSpw+WXX87gwYO55557XDYCsFgsfPXVV1StWpXLLruM3r1706BBAxYsWFCcH+28/P39+fHHH4mPj+eSSy7hpptu4qqrruKdd94577hff/2VunXrMnjwYJo3b86IESNIT08nODgYf39//vnnH2688UaaNGnCPffcw4MPPujcoODGG2+kf//+9OrVi+rVqzN//vx8r1OtWjUGDx7sXBJ47Ngxvv/+e2688cY8fS0WC4MHD3Y+0ykkJISVK1c6dzBs27Ytr776Ki+88AKPPPKIy7iPP/6YN954gy+//JLLL7+cNm3a8Nxzz3HdddfRr1/J3b83b948WrduTd++fenbty9t2rThww8/dOmzY8cOl4fXRkdHM3ToUJo1a8bYsWMZOnSoy89v48aN/P7772zdupVGjRpRs2ZN5+vQodwN1b7++mvq1q1Lz549S+zzAVjM6cWrlcTpKcrTWxmWJY9+9ieLU4dhsdh4vvvz3ND4BkdD/D54q52j/NgeCAhzW4wiIiIVRUZGBvv27aN+/foFLv8RKU5bt26ld+/e+W5GIReuc+fOjBs3jttvz3/n6XP9b70ouYFmnMqQhNQs7JmOpMhwRj579I/cspImERERkXKpdevWvPrqq+zfv9/doVQYx48f56abbuK2224r8Wtpc4gyJC41C4uXY6leVHBUbsPS5xzvVeuVekwiIiIiUnyGDRvm7hAqlPDwcB5//PFSuZZmnMoIYwxHEtPx8IkFwNvj1OYQtmxIPOgohzZ0U3QiIiIiIpWbEqcyYlt0Mkm+3zqPQ/1CHYXP7s7tdOOM0g1KREREREQAJU5lxrLtx/Gu+pvzuFZALchMgX++y+3kH+qGyERERERERIlTGbF8x3GM3QeApzo/5Xgw2pxBuR3uW+2myERERERERIlTGXEoIRUPr2QAmoaeelBYWkJuh4iWbohKRERERERAiVOZYIwhOfuY87hFtRaOQtKpTSGum+qGqERERERE5DQlTmXAycwcbNZY57Gfpx/8/VVuh7pdSz8oERERERFxUuJUBiSkZmPxyMitWDcdPjtjj/9q2oZcRERESsYVV1zBuHHj3B1GmfbMM89wzz33uDuMCuWmm27ijTfecHcYRaLEqQyIT8vC6udYltczsidE/5nbOFhbkIuIiIiru+++G4vFwssvv+xS/9VXXzk2mCqChQsX8sILLxRneHmcjvf0q1q1avTv358tW7aU6HWLw7Fjx/i///s/nn766Txtq1evxmq10r9//zxtK1aswGKxkJiYmKetXbt2PPfccy51mzZt4uabbyYiIgJfX1+aNGnC6NGj2blzZ3F9lHxNnTqV+vXr4+vrS8eOHVm5cuV5x8ybN4+2bdvi7+9PzZo1GT58OHFxcc72hQsX0qlTJ6pUqUJAQADt2rXjww8/dDnHs88+y3/+8x+Sk5OL/TOVFCVOZUBCWhbG7njg7bG0Y3Dod0fD5U9Cm5vdGJmIiIiUVb6+vrzyyiskJCScv/M5hIaGEhQUVExRFax///5ER0cTHR3NsmXL8PT05Oqrry7x616smTNn0q1bN+rVq5enbdasWTz00EOsWrWKgwcPXvA1vvvuO7p27UpmZibz5s1j+/btfPjhh4SEhPDMM89cRPTntmDBAsaNG8eECRPYtGkTPXv2ZMCAAef8LKtWreKuu+5i5MiR/P3333z22WesX7+eUaNGOfuEhoYyYcIE1qxZw5YtWxg+fDjDhw/nxx9/dPZp06YN9erVY968eSX2+YqbEqcyICE1Cyw2ALrU6AKxp/6y4OnjxqhEREQqIWMgK9U9L2OKFGrv3r2pUaMGkydPLrBPXFwct912G7Vr18bf35/WrVszf/58lz5nLtV76qmn6No1773Vbdq0YeLEic7j2bNn07x5c3x9fWnWrBlTp55/IysfHx9q1KhBjRo1aNeuHU888QSHDh3ixIkTzj5PPPEETZo0wd/fnwYNGvDMM8+QnZ0NwP79+/Hw8GDDhg0u53377beJiorCnPr5bdu2jYEDBxIYGEhERARDhw4lNjb3XvLPP/+c1q1b4+fnR7Vq1ejduzepqakFxv3JJ59w7bXX5qlPTU3l008/5b777uPqq69mzpw55/0Z5CctLY3hw4czcOBAvvnmG3r37k39+vXp0qULr732Gu+9994Fnbcw3njjDUaOHMmoUaNo3rw5U6ZMoU6dOkybNq3AMWvXrqVevXqMHTuW+vXrc+mll3Lvvfe6/LtcccUV3HDDDTRv3pyGDRvyr3/9izZt2rBq1SqXc1177bV5fh/LMk93ByAQdzILn7BfAPDOOuN/uC2uc1NEIiIilVR2GrxUyz3XfvooeAcUurvVauWll17i9ttvZ+zYsdSuXTtPn4yMDDp27MgTTzxBcHAw33//PUOHDqVBgwZ06dIlT/877riDl19+mT179tCwoeMe67///putW7fy+eefAzB9+nQmTpzIO++8Q/v27dm0aROjR48mICCAYcOG5Tlnfk6ePMm8efNo1KgR1apVc9YHBQUxZ84catWqxdatWxk9ejRBQUE8/vjj1KtXj969ezN79mw6derkHDN79mznUsDo6Gguv/xyRo8ezRtvvEF6ejpPPPEEt9xyCz///DPR0dHcdtttvPrqq9xwww2kpKSwcuVKZ9J1toSEBP766y+X6522YMECmjZtStOmTbnzzjt56KGHeOaZZ4q8VPLHH38kNjaWxx9/PN/2KlWqFDh2zJgxfPTRR+c8/7Zt26hbt26e+qysLDZu3MiTTz7pUt+3b19Wry74+aHdu3dnwoQJ/PDDDwwYMIDjx4/z+eefM2jQoHz7G2P4+eef2bFjB6+88opLW+fOnZk8eTKZmZn4+JT9CQMlTmXA5qOHnOXwmG25DdoUQkRERM7hhhtuoF27dkycOJGZM2fmaY+MjOTRRx91Hj/00EMsXryYzz77LN/EqVWrVrRp04aPP/7YuURs3rx5XHLJJTRp0gSAF154gddff53BgwcDUL9+fbZt28Z77713zsTpu+++IzAwEHDM1tSsWZPvvvsOD4/cBVD//ve/neV69erxyCOPsGDBAmdSMWrUKMaMGcMbb7yBj48Pf/75J5s3b2bhwoUATJs2jQ4dOvDSSy85zzNr1izq1KnDzp07OXnyJDk5OQwePJioqCgAWrduXWDMBw4cwBhDrVp5k+mZM2dy5513Ao5liCdPnmTZsmX07t27wPPlZ9euXQA0a9asSOMAnn/+eZd/3/zkFztAbGwsNpuNiIgIl/qIiAhiYmIKPF/37t2ZN28eQ4YMISMjg5ycHK699lrefvttl35JSUlERkaSmZmJ1Wpl6tSp9OnTx6XP6faYmBjnv0dZpsSpDNh6fDeEOMq3J8S7NxgREZHKzMvfMfPjrmtfgFdeeYUrr7ySRx55JE+bzWbj5ZdfZsGCBRw5coTMzEwyMzMJCCh4ZuuOO+5g1qxZPPPMMxhjmD9/vnMp34kTJzh06BAjR45k9OjRzjE5OTmEhIScM85evXo5l4DFx8czdepUBgwYwLp165xfmj///HOmTJnC7t27nUlOcHCw8xzXX389Dz74IF9++SW33nors2bNolevXs77jzZu3Mjy5cudCdqZ9uzZQ9++fbnqqqto3bo1/fr1o2/fvtx0001UrVo135jT09MBx/1kZ9qxYwfr1q1zJmyenp4MGTKEWbNmFTlxKmi2qzDCw8MJDw+/4PFAnhkyY8w5Z822bdvG2LFjefbZZ+nXrx/R0dE89thjjBkzxiV5DwoKYvPmzc6Ecvz48TRo0IArrrjC2cfPzw9wLFcsD5Q4uZndbjieFovX6f/WHDm1PvTS8W6LSUREpNKyWIq0XK4suOyyy+jXrx9PP/00d999t0vb66+/zptvvsmUKVNo3bo1AQEBjBs3jqysrALPd/vtt/Pkk0/yxx9/kJ6ezqFDh7j11lsBsNvtgGO53tkzVlar9ZxxBgQE0KhRI+dxx44dCQkJYfr06bz44ousXbuWW2+9lUmTJtGvXz9CQkL45JNPeP31151jvL29GTp0KLNnz2bw4MF8/PHHTJkyxdlut9u55ppr8iwJA6hZsyZWq5UlS5awevVqfvrpJ95++20mTJjA77//Tv369fOMCQsLAxxL9qpXr+6snzlzJjk5OURGRjrrjDF4eXmRkJBA1apVnQlfUlJSnuV2iYmJzkTz9EzeP//8Q7du3c75MzzbxSzVCwsLw2q15pldOn78eJ5ZqDNNnjyZHj168NhjjwGO+98CAgLo2bMnL774IjVr1gTAw8PD+e/drl07tm/fzuTJk10Sp/h4x4TBmT/bskyJk5slpmdj93Is1etUrTXsO7WLScMr3RiViIiIlCcvv/wy7dq1c34JP23lypVcd911ziVldrudXbt20bx58wLPVbt2bS677DLmzZtHeno6vXv3dn6RjoiIIDIykr1793LHHXdcVMwWiwUPDw/nrM5vv/1GVFQUEyZMcPY5cOBAnnGjRo2iVatWTJ06lezsbOeSQYAOHTrwxRdfUK9ePTw98/+aa7FY6NGjBz169ODZZ58lKiqKL7/8kvHj8/7RumHDhgQHB7Nt2zbnzzYnJ4e5c+fy+uuv07dvX5f+N954I/PmzePBBx+kcePGeHh4sH79epdlaNHR0Rw5coSmTZsCjnuKwsLCePXVV/nyyy/zxJCYmFjgfU4Xs1TP29ubjh07smTJEm644QZn/ZIlS7juuoLvs09LS8vzsz2dNJ9r9swYQ2ZmpkvdX3/9Re3atZ0JalmnxMnNjDF4+Dh2k7El7MttqJN33bGIiIhIflq3bs0dd9yR5z6TRo0a8cUXX7B69WqqVq3KG2+8QUxMzDkTJ3As13vuuefIysrizTffdGl77rnnGDt2LMHBwQwYMIDMzEw2bNhAQkJCvsnHaafvZQHHDM4777zDyZMnueaaa5yxHjx4kE8++YRLLrmE77//Pt9Eonnz5nTt2pUnnniCESNGOJd7ATzwwANMnz6d2267jccee4ywsDB2797NJ598wvTp09mwYQPLli2jb9++hIeH8/vvv3PixIkCfx4eHh707t2bVatWcf311wOOe7USEhIYOXJknuWJN910EzNnzuTBBx8kKCiIe++9l0ceeQRPT0/atm3L0aNHmTBhAs2bN3cmXQEBAcyYMYObb76Za6+9lrFjx9KoUSNiY/+/vTsPi+o6/wD+HYZt2BVRVlFRROIu7lVrQlxwi4lKoxE0akIUCeKaxhSiTWxiReJuGpZqMbihSaOJWqMoag0i1gWqJCGuEOvGoiwy8/7+8MfEERAHhQH5fp5nnod77jn3vHfmgPf13HvmBrZs2aJ9TyrytLfqhYWFYeLEifDx8UHv3r3x+eef49KlSwgKCtLWee+993D16lVs2LABADBixAhMmzYNa9eu1d6qFxoaih49emiTtCVLlsDHxwceHh4oKSnB7t27sWHDhnKr9R0+fLhc8lmnSQOTm5srACQ3N9fQoYiISPadQmm74nVpH9de5sd0Fwm3EYkbYeiwiIiInnuFhYWSnp4uhYWFhg5Fb4GBgTJq1Cidsl9++UXMzMzk4cu7mzdvyqhRo8TKykqaNm0qCxculICAAJ22AwYMkHfffVfnWLdv3xYzMzOxsLCQ/Pz8cv3Hx8dL586dxdTUVBo1aiT9+/eXxMTEx8YLQPuytraW7t27y7Zt23TqzZ07V+zt7cXKykr8/f1l+fLlYmtrW+540dHRAkB++OGHcvsuXLggo0ePFjs7O1GpVOLl5SWhoaGi0WgkPT1dBg8eLA4ODmJmZiaenp6ycuXKSuMWEfnuu+/ExcVF1Gq1iIgMHz5c/Pz8KqybmpoqACQ1NVVERIqKimTRokXSrl07UalU4u7uLpMmTZLs7OxybVNSUuTVV1/Vxta6dWt56623JDMz87HxPa3Vq1eLu7u7mJqaSteuXSUpKUlnf2BgoAwYMECnbMWKFeLt7S0qlUqcnJxkwoQJcuXKFe3+999/X1q3bi3m5ubSqFEj6d27tyQkJOgco7CwUGxsbOTYsWM1dm4P91XZ77o+uYFC5CmeSKuH8vLyYGtri9zcXJ2HDQ3l+M83EbgrGCY2ZzEv/z4m3sgGhnwC9AqqujERERFVW1FREbKystCyZctyD/9T3fbRRx8hISEBZ86cqfG+RAS9evVCaGgoXn/99Rrvr6FYvXo1vvrqK+zdu7fG+3rc77o+uQG/ANfAiks12i+/tSjKe1DYqIXhAiIiIiKqowoKCpCSkoKVK1ciJCSkVvpUKBT4/PPPUVpaWiv9NRQmJiblbi2t6/iMk4GpRWBseQHAQx+GWw+DxUNERERUVwUHB+PLL7/EK6+8gjfffLPW+u3UqRM6depUa/01BG+99ZahQ9AbEycD02gECqMHM05GZXdNWjQ2YEREREREdVNcXBzi4uIMHQY1ULxVz8BK1Rrtz+1K7hswEiIiIiIiqgwTJwMr0fy2nr1jaSnQ8Q8GjIaIiIiIiCrCxMnACu4XaH82EwGsqr8WPxERERER1QwmTgZ2q/i69mcTAOjEGSciIiIiorqGiZOBXSn4GQDgcv//l7h0ePw3eRMRERERUe1j4mRgt++VAADuK/6/wIgfCRERERFRXcOrdAPLKjgLAOhcVAy0GmjgaIiIiOh5FhERgc6dOxs6jBo3ceJEfPzxx4YO47nSvXt3JCYmGjoMg2LiZGA3StMBAIVGRoCrj4GjISIiovrk6NGjUCqVGDJkSI310aJFCygUCigUCiiVSjg7O2PKlCm4fft2jfX5qIMHD0KhUODOnTtV1j19+jR27dqFmTNnltu3adMmKJVKBAUFldsXFxcHOzu7Co9pZ2dX7vujDhw4AD8/P9jb28PCwgLe3t6YPXs2rl69+iSnVC0igoiICDg7O0OlUuH3v/89zp0799g29+/fx6JFi+Dh4QFzc3N06tQJ3333nU6dJUuWoHv37rC2tkbTpk3xyiuv4Pz58zp1PvjgAyxYsAAajQYNFRMnAytR3AQAdCguBpy7GDgaIiIiqk9iYmIwc+ZMJCcn49KlSzXWz6JFi5CdnY1Lly4hPj4ehw4dQkhISI319zRWrVqFsWPHwtrauty+mJgYzJs3DwkJCbh37161+1i/fj18fX3h6OiI7du3Iz09HevWrUNubi6WLVv2NOE/1qefforIyEisWrUKKSkpcHR0xMsvv4z8/PxK2yxcuBDr16/HypUrkZ6ejqCgIIwePRppaWnaOklJSZgxYwb+/e9/Y9++fSgtLcWgQYNw9+5dbZ1hw4YhNzcXe/bsqbHzq/OkgcnNzRUAkpuba+hQpFRdKu3j2kv7uPZyeXEjkcx9hg6JiIiowSgsLJT09HQpLCzUlmk0GrlbctcgL41Go1f8BQUFYm1tLf/973/F399fPvzww3J1lixZIk2bNhUrKyt58803Zf78+dKpUyft/h9++EF8fX3F3t5ebGxspH///pKamqpzDHd3d1m+fLlO2aJFi8Tb21unbNu2beLt7S2mpqbi7u4uf/3rX3X237p1SyZOnCh2dnaiUqlkyJAhcuHCBe3+X375RYYPHy52dnZiYWEh3t7esmvXLsnKyhIAOq/AwMAK3xO1Wi12dnbyzTfflNuXlZUlKpVK7ty5Iz179pS///3vOvtjY2PF1ta2wuPa2tpKbGysiIhcvnxZTE1NJTQ0tMK6t2/frrD8aWk0GnF0dJS//OUv2rKioiKxtbWVdevWVdrOyclJVq1apVM2atQomTBhQqVtrl+/LgAkKSlJp3zSpEkyceLEap6B4VT0u15Gn9zA2IA5GwBgzZo1WLp0KbKzs/HCCy8gKioK/fr1q7R+UlISwsLCcO7cOTg7O2PevHkVTrfWB1m5WdqfHdRqoLGHAaMhIiKiwtJC9NzU0yB9Hx9/HBYmFk9cf/PmzWjbti3atm2LN954AzNnzsQHH3wAheLBilNbtmxBeHg4Vq9ejX79+mHjxo1YsWIFWrVqpT1Gfn4+AgMDsWLFCgDAsmXL4Ofnh8zMzApnbADg6tWr+Oabb9Cz52/vU2pqKsaNG4eIiAj4+/vj6NGjmD59Ouzt7TFp0iQAwKRJk5CZmYmvv/4aNjY2mD9/Pvz8/JCeng4TExPMmDEDJSUlOHToECwtLZGeng4rKyu4ublh+/bteO2113D+/HnY2NhApVJVGNvp06dx584d+PiUf/whJiYGw4YNg62tLd544w1ER0cjICDgid/vMlu3bkVJSQnmzZtX4f7KbvcDgKFDh+Lw4cOPPX5BQUGF5VlZWcjJycGgQYO0ZWZmZhgwYACOHj2Kt99+u8J2xcXFMDc31ylTqVRITk6uNIbc3FwAQOPGjXXKe/TogU8//fSx8T/PDJo4bd68GaGhoVizZg369u2L9evXY+jQoUhPT0fz5s3L1c/KyoKfnx+mTZuGf/zjHzhy5AimT58OBwcHvPbaawY4g6eTdeeK9mczAdC4peGCISIionolOjoab7zxBgBgyJAhKCgowP79++Hr6wsAiIqKwptvvompU6cCAP785z/jX//6F4qKirTHePHFF3WOuX79ejRq1AhJSUkYPny4tnz+/PlYuHAh1Go1ioqK0LNnT0RGRmr3R0ZG4qWXXsIHH3wAAPD09ER6ejqWLl2qkzAdOXIEffr0AQDEx8fDzc0NO3fuxNixY3Hp0iW89tpr6NChAwDoJHhlF/BNmzZ9bGLyyy+/QKlUomnTpjrlGo0GcXFxWLlyJQDgD3/4A8LCwvDjjz+idevWVb3VOjIzM2FjYwMnJye92gHAF198gcLCQr3bAUBOTg4AoFmzZjrlzZo1w8WLFyttN3jwYERGRqJ///7w8PDA/v378dVXX0GtVldYX0QQFhaG3/3ud2jfvr3OPhcXF1y6dAkajQZGDXAlaIMmTpGRkZgyZYr2FzoqKgp79uzB2rVrsWTJknL1161bh+bNmyMqKgoA0K5dO5w4cQJ//etf62XidCYnGwBg3oAfsiMiIqpLVMYqHB9/3GB9P6nz58/jhx9+0K5yZmxsDH9/f8TExGgTp4yMjHJ35fTu3RsHDhzQbl+/fh1/+tOf8P333+PXX3+FWq3GvXv3yj0vNXfuXEyaNAkigsuXL+OPf/wjhg0bhkOHDkGpVCIjIwOjRo3SadO3b19ERUVBrVYjIyMDxsbGOrNU9vb2aNu2LTIyMgAAISEheOedd7B37174+vritddeQ8eOHZ/4PQGAwsJCmJmZaWfdyuzduxd3797F0KFDAQBNmjTBoEGDEBMTo/fqeyJS7vhPysXFpVrtHvZo31XF89lnn2HatGnw8vKCQqGAh4cHJk+ejNjY2ArrBwcH4/Tp0xXOSKlUKmg0GhQXF1c66/c8M1jiVFJSgtTUVCxYsECnfNCgQTh69GiFbY4dO6YzPQk8yKKjo6Nx//59mJiYlGtTXFyM4uJi7XZeXt4ziP7ZKPn1wR8Kz5L7wMCFBo6GiIiIFAqFXrfLGUp0dDRKS0t1LsRFBCYmJrh9+zYaNWr0RMeZNGkS/ve//yEqKgru7u4wMzND7969UVJSolOvSZMm2pmZNm3aICoqSpuE+fr6VnjxLiIV/vxonbJ2U6dOxeDBg7Fr1y7s3bsXS5YswbJlyypcHa8yTZo0wb1791BSUgJTU1NteUxMDG7dugULi98+W41Gg7S0NCxevBhKpRI2NjYoKCiAWq2GUqnU1lOr1SgoKICtrS2AB7Npubm5yM7O1nvW6Wlu1XN0dATwYObp4X6vX79ebhbqYQ4ODti5cyeKiopw8+ZNODs7Y8GCBWjZsvydTjNnzsTXX3+NQ4cOwdXVtdz+svewISZNgAFX1btx4wbUanWF041lU5GPysnJqbB+aWkpbty4UWGbJUuWwNbWVvtyc3N7NifwLORlAgAaiTnQfYqBgyEiIqL6oLS0FBs2bMCyZctw6tQp7es///kP3N3dER8fD+DBnTn//ve/ddo+un348GGEhITAz88PL7zwAszMzCq9pnpYWWJRdtuZt7d3uRmKo0ePwtPTE0qlEt7e3igtLcXx47/N5t28eRMXLlxAu3bttGVubm4ICgpCYmIiZs+ejb/97W8AoE2CKru9rEzZd1Slp6fr9PPVV18hISFB5/06deoUCgoK8O233wIAvLy8oFardVabA4CTJ09CrVajbdu2AIAxY8bA1NS00md9Hrdk+hdffFEuhkdflWnZsiUcHR2xb98+bVlJSQmSkpK0tz8+jrm5OVxcXFBaWort27frzBCKCIKDg5GYmIjvv/++wqQKAM6ePYuuXbtW2dfzyuCLQ+g73VjZ/2ZU1ua9995DWFiYdjsvL6/OJE8jBi2B19EVMOn2KmDRuOoGRERE1OB98803uH37NqZMmaKdBSkzZswYREdHIzg4GO+++y4CAwPh4+OD3/3ud4iPj8e5c+d0nh1q3bo1Nm7cCB8fH+Tl5WHu3LkVzibk5+cjJydHe6vevHnz0KRJE+0F++zZs9G9e3csXrwY/v7+OHbsGFatWoU1a9YAeDBLNWrUKEybNg3r16+HtbU1FixYABcXF+0FfGhoKIYOHQpPT0/cvn0b33//vTapcnd3h0KhwDfffAM/Pz+oVCpYWVmVi9PBwQFdu3ZFcnKyNonauHEj7O3tMXbs2HLP5QwfPhzR0dEYPnw4vL29MXToULz55puIjIyEh4cHfvrpJ4SFhWHo0KHw9vYG8CC5W758OYKDg5GXl4eAgAC0aNECV65cwYYNG2BlZVXpkuRPc6ueQqFAaGgoPv74Y7Rp0wZt2rTBxx9/DAsLC4wfP15bLyAgAC4uLtrHXo4fP46rV6+ic+fOuHr1KiIiIqDRaHQWt5gxYwY2bdqEr776CtbW1tpJDFtbW53xcPjw4XJ3fzUoz2iVP70VFxeLUqmUxMREnfKQkBDp379/hW369esnISEhOmWJiYlibGwsJSUlT9RvXVqOnIiIiAzncUsU12XDhw8XPz+/CvelpqYKAO2S4h999JE0adJErKysJDAwUObNm6ezHPnJkyfFx8dHzMzMpE2bNrJ169Zyy4+7u7vrLAXu4OAgfn5+kpaWptN32XLkJiYm0rx5c1m6dKnO/rLlyG1tbUWlUsngwYN1liMPDg4WDw8PMTMzEwcHB5k4caLcuHFDu3/RokXi6OgoCoWi0uXIRUTWrVsnvXr10m536NBBpk+fXmHd7du3i7GxseTk5IjIg+vEWbNmSevWrcXc3Fxat24toaGhcufOnXJt9+3bJ4MHD5ZGjRqJubm5eHl5yZw5c+TatWuVxva0NBqNhIeHi6Ojo5iZmUn//v3lzJkzOnUGDBig8/4cPHhQ2rVrJ2ZmZmJvby8TJ06Uq1ev6rTBI8u9l73KlmAXEbly5YqYmJjI5cuXa+z8asqzWo5cIVLJTae1oGfPnujWrZv2fyOAB1O9o0aNqnBxiPnz5+Of//ynzvTrO++8g1OnTuHYsWNP1GdeXh5sbW2Rm5sLGxubpz8JIiIiqpeKioqQlZWFli1blluumeqvoqIitG3bFgkJCejdu7ehw3luzJ07F7m5ufj8888NHYreHve7rk9uYNB1BMPCwvDFF18gJiYGGRkZmDVrFi5duqRdAea9997TWV8/KCgIFy9eRFhYGDIyMhATE4Po6GjMmTPHUKdARERERHWIubk5NmzY8ETPatGTa9q0KRYvXmzoMAzKoM84+fv74+bNm1i0aBGys7PRvn177N69G+7u7gCA7OxsneUwW7Zsid27d2PWrFlYvXo1nJ2dsWLFinq5FDkRERER1YwBAwYYOoTnzty5cw0dgsEZ9FY9Q+CtekRERATwVj2ihuK5uFWPiIiIiIioPmDiRERERA1aA7v5hqjBeVa/40yciIiIqEEyMTEBANy7d8/AkRBRTSopKQHw2xc3V5fBvwCXiIiIyBCUSiXs7Oxw/fp1AICFhQUUCoWBoyKiZ0mj0eB///sfLCwsYGz8dKkPEyciIiJqsBwdHQFAmzwR0fPHyMgIzZs3f+r/GGHiRERERA2WQqGAk5MTmjZtivv37xs6HCKqAaampjAyevonlJg4ERERUYOnVCqf+vkHInq+cXEIIiIiIiKiKjBxIiIiIiIiqgITJyIiIiIioio0uGecyr4AKy8vz8CREBERERGRIZXlBE/yJbkNLnHKz88HALi5uRk4EiIiIiIiqgvy8/Nha2v72DoKeZL06jmi0Whw7do1WFtb14kvucvLy4ObmxsuX74MGxsbQ4dD9QDHDOmD44X0xTFD+uKYIX3VpTEjIsjPz4ezs3OVS5Y3uBknIyMjuLq6GjqMcmxsbAw+cKh+4ZghfXC8kL44ZkhfHDOkr7oyZqqaaSrDxSGIiIiIiIiqwMSJiIiIiIioCkycDMzMzAzh4eEwMzMzdChUT3DMkD44XkhfHDOkL44Z0ld9HTMNbnEIIiIiIiIifXHGiYiIiIiIqApMnIiIiIiIiKrAxImIiIiIiKgKTJyIiIiIiIiqwMSphq1ZswYtW7aEubk5unXrhsOHDz+2flJSErp16wZzc3O0atUK69atq6VIqa7QZ8wkJibi5ZdfhoODA2xsbNC7d2/s2bOnFqOlukDfvzNljhw5AmNjY3Tu3LlmA6Q6R98xU1xcjPfffx/u7u4wMzODh4cHYmJiailaqgv0HTPx8fHo1KkTLCws4OTkhMmTJ+PmzZu1FC0Z2qFDhzBixAg4OztDoVBg586dVbapD9fATJxq0ObNmxEaGor3338faWlp6NevH4YOHYpLly5VWD8rKwt+fn7o168f0tLS8Mc//hEhISHYvn17LUdOhqLvmDl06BBefvll7N69G6mpqRg4cCBGjBiBtLS0Wo6cDEXfMVMmNzcXAQEBeOmll2opUqorqjNmxo0bh/379yM6Ohrnz5/Hl19+CS8vr1qMmgxJ3zGTnJyMgIAATJkyBefOncPWrVuRkpKCqVOn1nLkZCh3795Fp06dsGrVqieqX2+ugYVqTI8ePSQoKEinzMvLSxYsWFBh/Xnz5omXl5dO2dtvvy29evWqsRipbtF3zFTE29tbPvzww2cdGtVR1R0z/v7+snDhQgkPD5dOnTrVYIRU1+g7Zr799luxtbWVmzdv1kZ4VAfpO2aWLl0qrVq10ilbsWKFuLq61liMVHcBkB07djy2Tn25BuaMUw0pKSlBamoqBg0apFM+aNAgHD16tMI2x44dK1d/8ODBOHHiBO7fv19jsVLdUJ0x8yiNRoP8/Hw0bty4JkKkOqa6YyY2NhY//fQTwsPDazpEqmOqM2a+/vpr+Pj44NNPP4WLiws8PT0xZ84cFBYW1kbIZGDVGTN9+vTBlStXsHv3bogIfv31V2zbtg3Dhg2rjZCpHqov18DGhg7geXXjxg2o1Wo0a9ZMp7xZs2bIycmpsE1OTk6F9UtLS3Hjxg04OTnVWLxkeNUZM49atmwZ7t69i3HjxtVEiFTHVGfMZGZmYsGCBTh8+DCMjflPQENTnTHz888/Izk5Gebm5tixYwdu3LiB6dOn49atW3zOqQGozpjp06cP4uPj4e/vj6KiIpSWlmLkyJFYuXJlbYRM9VB9uQbmjFMNUygUOtsiUq6sqvoVldPzS98xU+bLL79EREQENm/ejKZNm9ZUeFQHPemYUavVGD9+PD788EN4enrWVnhUB+nzd0aj0UChUCA+Ph49evSAn58fIiMjERcXx1mnBkSfMZOeno6QkBD86U9/QmpqKr777jtkZWUhKCioNkKleqo+XAPzvxtrSJMmTaBUKsv9b8z169fLZdRlHB0dK6xvbGwMe3v7GouV6obqjJkymzdvxpQpU7B161b4+vrWZJhUh+g7ZvLz83HixAmkpaUhODgYwIOLYhGBsbEx9u7dixdffLFWYifDqM7fGScnJ7i4uMDW1lZb1q5dO4gIrly5gjZt2tRozGRY1RkzS5YsQd++fTF37lwAQMeOHWFpaYl+/frhz3/+c52ZPaC6o75cA3PGqYaYmpqiW7du2Ldvn075vn370KdPnwrb9O7du1z9vXv3wsfHByYmJjUWK9UN1RkzwIOZpkmTJmHTpk28f7yB0XfM2NjY4MyZMzh16pT2FRQUhLZt2+LUqVPo2bNnbYVOBlKdvzN9+/bFtWvXUFBQoC27cOECjIyM4OrqWqPxkuFVZ8zcu3cPRka6l5hKpRLAb7MIRA+rN9fABlqUokFISEgQExMTiY6OlvT0dAkNDRVLS0v55ZdfRERkwYIFMnHiRG39n3/+WSwsLGTWrFmSnp4u0dHRYmJiItu2bTPUKVAt03fMbNq0SYyNjWX16tWSnZ2tfd25c8dQp0C1TN8x8yiuqtfw6Dtm8vPzxdXVVcaMGSPnzp2TpKQkadOmjUydOtVQp0C1TN8xExsbK8bGxrJmzRr56aefJDk5WXx8fKRHjx6GOgWqZfn5+ZKWliZpaWkCQCIjIyUtLU0uXrwoIvX3GpiJUw1bvXq1uLu7i6mpqXTt2lWSkpK0+wIDA2XAgAE69Q8ePChdunQRU1NTadGihaxdu7aWIyZD02fMDBgwQACUewUGBtZ+4GQw+v6deRgTp4ZJ3zGTkZEhvr6+olKpxNXVVcLCwuTevXu1HDUZkr5jZsWKFeLt7S0qlUqcnJxkwoQJcuXKlVqOmgzlwIEDj70+qa/XwAoRzpkSERERERE9Dp9xIiIiIiIiqgITJyIiIiIioiowcSIiIiIiIqoCEyciIiIiIqIqMHEiIiIiIiKqAhMnIiIiIiKiKjBxIiIiIiIiqgITJyIiIiIioiowcSIiomqJi4uDnZ2docOothYtWiAqKuqxdSIiItC5c+daiYeIiOo2Jk5ERA3YpEmToFAoyr1+/PFHQ4eGuLg4nZicnJwwbtw4ZGVlPZPjp6Sk4K233tJuKxQK7Ny5U6fOnDlzsH///mfSX2UePc9mzZphxIgROHfunN7Hqc+JLBFRXcfEiYiogRsyZAiys7N1Xi1btjR0WAAAGxsbZGdn49q1a9i0aRNOnTqFkSNHQq1WP/WxHRwcYGFh8dg6VlZWsLe3f+q+qvLwee7atQt3797FsGHDUFJSUuN9ExHRk2HiRETUwJmZmcHR0VHnpVQqERkZiQ4dOsDS0hJubm6YPn06CgoKKj3Of/7zHwwcOBDW1tawsbFBt27dcOLECe3+o0ePon///lCpVHBzc0NISAju3r372NgUCgUcHR3h5OSEgQMHIjw8HGfPntXOiK1duxYeHh4wNTVF27ZtsXHjRp32ERERaN68OczMzODs7IyQkBDtvodv1WvRogUAYPTo0VAoFNrth2/V27NnD8zNzXHnzh2dPkJCQjBgwIBndp4+Pj6YNWsWLl68iPPnz2vrPO7zOHjwICZPnozc3FztzFVERAQAoKSkBPPmzYOLiwssLS3Rs2dPHDx48LHxEBFReUyciIioQkZGRlixYgXOnj2Lv//97/j+++8xb968SutPmDABrq6uSElJQWpqKhYsWAATExMAwJkzZzB48GC8+uqrOH36NDZv3ozk5GQEBwfrFZNKpQIA3L9/Hzt27MC7776L2bNn4+zZs3j77bcxefJkHDhwAACwbds2LF++HOvXr0dmZiZ27tyJDh06VHjclJQUAEBsbCyys7O12w/z9fWFnZ0dtm/fri1Tq9XYsmULJkyY8MzO886dO9i0aRMAaN8/4PGfR58+fRAVFaWducrOzsacOXMAAJMnT8aRI0eQkJCA06dPY+zYsRgyZAgyMzOfOCYiIgIgRETUYAUGBopSqRRLS0vta8yYMRXW3bJli9jb22u3Y2NjxdbWVrttbW0tcXFxFbadOHGivPXWWzplhw8fFiMjIyksLKywzaPHv3z5svTq1UtcXV2luLhY+vTpI9OmTdNpM3bsWPHz8xMRkWXLlomnp6eUlJRUeHx3d3dZvny5dhuA7NixQ6dOeHi4dOrUSbsdEhIiL774onZ7z549YmpqKrdu3Xqq8wQglpaWYmFhIQAEgIwcObLC+mWq+jxERH788UdRKBRy9epVnfKXXnpJ3nvvvccen4iIdBkbNm0jIiJDGzhwINauXavdtrS0BAAcOHAAH3/8MdLT05GXl4fS0lIUFRXh7t272joPCwsLw9SpU7Fx40b4+vpi7Nix8PDwAACkpqbixx9/RHx8vLa+iECj0SArKwvt2rWrMLbc3FxYWVlBRHDv3j107doViYmJMDU1RUZGhs7iDgDQt29ffPbZZwCAsWPHIioqCq1atcKQIUPg5+eHESNGwNi4+v/0TZgwAb1798a1a9fg7OyM+Ph4+Pn5oVGjRk91ntbW1jh58iRKS0uRlJSEpUuXYt26dTp19P08AODkyZMQEXh6euqUFxcX18qzW0REzxMmTkREDZylpSVat26tU3bx4kX4+fkhKCgIixcvRuPGjZGcnIwpU6bg/v37FR4nIiIC48ePx65du/Dtt98iPDwcCQkJGD16NDQaDd5++22dZ4zKNG/evNLYyhIKIyMjNGvWrFyCoFAodLZFRFvm5uaG8+fPY9++ffjXv/6F6dOnY+nSpUhKStK5BU4fPXr0gIeHBxISEvDOO+9gx44diI2N1e6v7nkaGRlpPwMvLy/k5OTA398fhw4dAlC9z6MsHqVSidTUVCiVSp19VlZWep07EVFDx8SJiIjKOXHiBEpLS7Fs2TIYGT14HHbLli1VtvP09ISnpydmzZqF119/HbGxsRg9ejS6du2Kc+fOlUvQqvJwQvGodu3aITk5GQEBAdqyo0eP6szqqFQqjBw5EiNHjsSMGTPg5eWFM2fOoGvXruWOZ2Ji8kSr9Y0fPx7x8fFwdXWFkZERhg0bpt1X3fN81KxZsxAZGYkdO3Zg9OjRT/R5mJqalou/S5cuUKvVuH79Ovr16/dUMRERNXRcHIKIiMrx8PBAaWkpVq5ciZ9//hkbN24sd+vYwwoLCxEcHIyDBw/i4sWLOHLkCFJSUrRJzPz583Hs2DHMmDEDp06dQmZmJr7++mvMnDmz2jHOnTsXcXFxWLduHTIzMxEZGYnExETtoghxcXGIjo7G2bNnteegUqng7u5e4fFatGiB/fv3IycnB7dv36603wkTJuDkyZP46KOPMGbMGJibm2v3PavztLGxwdSpUxEeHg4ReaLPo0WLFigoKMD+/ftx48YN3Lt3D56enpgwYQICAgKQmJiIrKwspKSk4JNPPsHu3bv1iomIqKFj4kREROV07twZkZGR+OSTT9C+fXvEx8djyZIlldZXKpW4efMmAgIC4OnpiXHjxmHo0KH48MMPAQAdO3ZEUlISMjMz0a9fP3Tp0gUffPABnJycqh3jK6+8gs8++wxLly7FCy+8gPXr1yM2Nha///3vAQB2dnb429/+hr59+6Jjx47Yv38//vnPf1b6bM+yZcuwb98+uLm5oUuXLpX226ZNG3Tv3h2nT5/WrqZX5lme57vvvouMjAxs3br1iT6PPn36ICgoCP7+/nBwcMCnn34K4MFKgQEBAZg9ezbatm2LkSNH4vjx43Bzc9M7JiKihkwhImLoIIiIiIiIiOoyzjgRERERERFVgYkTERERERFRFZg4ERERERERVYGJExERERERURWYOBEREREREVWBiRMREREREVEVmDgRERERERFVgYkTERERERFRFZg4ERERERERVYGJExERERERURWYOBEREREREVXh/wBupvoWuEpUJgAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now we will plot the time needed to train the models comparing AdaBoost with the best hyperparameters and Random Forest, Naive Bayes and svc.",
   "id": "9758c29d51459b04"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-11T15:11:20.475452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "#Train the models with the best hyperparameters\n",
    "ada=AdaBoostClassifier(**ada_best_params)\n",
    "rf=RandomForestClassifier(**rf_best_params)\n",
    "svc=SVC(probability=True, kernel='linear')\n",
    "nv=GaussianNB(**nb_best_params)\n",
    "#Train svc\n",
    "\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "ada.fit(X_train,y_train)\n",
    "end=time.time()\n",
    "ada_time=end-start\n",
    "\n",
    "start=time.time()\n",
    "rf.fit(X_train,y_train)\n",
    "end=time.time()\n",
    "rf_time=end-start\n",
    "\n",
    "start=time.time()\n",
    "svc.fit(X_train,y_train)\n",
    "end=time.time()\n",
    "svc_time=end-start\n",
    "\n",
    "start=time.time()\n",
    "nv.fit(X_train,y_train)\n",
    "end=time.time()\n",
    "nv_time=end-start\n",
    "\n",
    "times=[ada_time,rf_time,svc_time,nv_time]\n",
    "\n",
    "plt.bar(['AdaBoost','Random Forest','SVC','Naive Bayes'],times)\n",
    "plt.title(\"Training time (seconds)\")\n"
   ],
   "id": "539bc84da1fea0dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Store training times in a list\n",
    "times = [ada_time, rf_time, svc_time, nv_time]\n",
    "\n",
    "# Plot training times on a log scale\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['AdaBoost', 'Random Forest', 'SVC', 'Naive Bayes'], times)\n",
    "plt.yscale('log')  # Set y-axis to logarithmic scale\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Training Time (seconds, log scale)\")\n",
    "plt.title(\"Training Time Comparison on Log Scale\")\n",
    "plt.show()"
   ],
   "id": "2851ef8283262ccc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### And finally, we will plot the time needed for a new prediction to be made by the models.",
   "id": "82e64d284399578e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Time predictions for each model\n",
    "\n",
    "start = time.time()\n",
    "ada.predict(X_test)\n",
    "end = time.time()\n",
    "ada_pred_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "rf.predict(X_test)\n",
    "end = time.time()\n",
    "rf_pred_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "svc.predict(X_test)\n",
    "end = time.time()\n",
    "svc_pred_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "nv.predict(X_test)\n",
    "end = time.time()\n",
    "nv_pred_time = end - start\n",
    "\n",
    "# Store prediction times in a list\n",
    "times = [ada_pred_time, rf_pred_time, svc_pred_time, nv_pred_time]\n",
    "\n",
    "# Plot prediction times on a log scale\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['AdaBoost', 'Random Forest', 'SVC', 'Naive Bayes'], times)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Prediction Time (seconds)\")\n",
    "plt.title(\"Prediction Time Comparison on Log Scale\")\n",
    "plt.show()"
   ],
   "id": "3d9009568f6e2601",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import iris setosa dataset, and do logistic regression\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n"
   ],
   "id": "98bff61f00de533d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
